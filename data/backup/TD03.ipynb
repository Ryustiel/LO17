{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:12.542322Z",
     "start_time": "2025-03-26T22:08:12.102990Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mindex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BS4Parser, Corpus\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Configuration des chemins\u001b[39;00m\n\u001b[32m     28\u001b[39m BASE_DIR = os.getcwd() \u001b[38;5;66;03m# Ou spécifiez un chemin absolu\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\index\\__init__.py:3\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransactions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclients\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\index\\clients\\__init__.py:2\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbs4_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BS4Parser\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtdf_calculator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CorpusTFIDFCalculator\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocess_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileProcessClient\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\index\\clients\\bs4_parser.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocess_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileProcessClient\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransactions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document, Image\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\.venv\\Lib\\site-packages\\bs4\\__init__.py:64\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.version_info.major < \u001b[32m3\u001b[39m:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     61\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to use a Python 3-specific version of Beautiful Soup under Python 2. This will not work. The final version of Beautiful Soup to support Python 2 was 4.9.3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     65\u001b[39m     builder_registry,\n\u001b[32m     66\u001b[39m     TreeBuilder,\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_htmlparser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTMLParserTreeBuilder\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdammit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnicodeDammit\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\.venv\\Lib\\site-packages\\bs4\\builder\\__init__.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01melement\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     AttributeDict,\n\u001b[32m     26\u001b[39m     AttributeValueList,\n\u001b[32m     27\u001b[39m     CharsetMetaAttributeValue,\n\u001b[32m     28\u001b[39m     ContentMetaAttributeValue,\n\u001b[32m     29\u001b[39m     RubyParenthesisString,\n\u001b[32m     30\u001b[39m     RubyTextString,\n\u001b[32m     31\u001b[39m     Stylesheet,\n\u001b[32m     32\u001b[39m     Script,\n\u001b[32m     33\u001b[39m     TemplateString,\n\u001b[32m     34\u001b[39m     nonwhitespace_re,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Exceptions were moved to their own module in 4.13. Import here for\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# backwards compatibility.\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParserRejectedMarkup\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\GitHub\\UTC\\LO17\\PremierDM\\.venv\\Lib\\site-packages\\bs4\\element.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CSS\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_deprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     _deprecated,\n\u001b[32m     12\u001b[39m     _deprecated_alias,\n\u001b[32m     13\u001b[39m     _deprecated_function_alias,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformatter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     Formatter,\n\u001b[32m     17\u001b[39m     HTMLFormatter,\n\u001b[32m     18\u001b[39m     XMLFormatter,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_warnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttributeResemblesVariableWarning\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1322\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1262\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1528\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1502\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1601\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # LO17 - TD2 & TD3 : Préparation et Filtrage du Corpus ADIT\n",
    "#\n",
    "# Ce notebook met en œuvre les étapes décrites dans les TD2 et TD3 en utilisant les classes Python créées.\n",
    "#\n",
    "# **Objectifs :**\n",
    "# 1.  **TD2 : Préparation du Corpus**\n",
    "#     *   Parser les fichiers HTML des bulletins ADIT.\n",
    "#     *   Extraire les informations structurées (métadonnées, texte, images, etc.).\n",
    "#     *   Générer un fichier XML unique (`corpus_initial.xml`) contenant tous les articles parsés.\n",
    "# 2.  **TD3 : Anti-dictionnaire et Filtrage**\n",
    "#     *   Définir l'unité documentaire (ici, l'article/bulletin individuel).\n",
    "#     *   Segmenter le corpus en tokens (`token`, `document_id`).\n",
    "#     *   Calculer TF, IDF et TF-IDF.\n",
    "#     *   Générer un anti-dictionnaire basé sur un seuil IDF.\n",
    "#     *   Appliquer les substitutions (suppressions) de l'anti-dictionnaire au corpus en mémoire.\n",
    "#     *   Sauvegarder le corpus filtré dans un nouveau fichier XML (`corpus_filtre.xml`).\n",
    "\n",
    "# ## 1. Importations et Configuration\n",
    "\n",
    "# +\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from index import BS4Parser, Corpus\n",
    "\n",
    "\n",
    "# Configuration des chemins\n",
    "BASE_DIR = os.getcwd() # Ou spécifiez un chemin absolu\n",
    "DATA_FOLDER = os.path.join(BASE_DIR, \"data\", \"BULLETINS\")\n",
    "OUTPUT_FOLDER = os.path.join(BASE_DIR, \"output\")\n",
    "XML_INITIAL_FILE = os.path.join(OUTPUT_FOLDER, \"corpus_initial.xml\")\n",
    "XML_FILTRE_FILE = os.path.join(OUTPUT_FOLDER, \"corpus_filtre.xml\")\n",
    "SEGMENTATION_FILE = os.path.join(OUTPUT_FOLDER, \"segmentation.tsv\")\n",
    "TF_FILE = os.path.join(OUTPUT_FOLDER, \"tf.tsv\")\n",
    "IDF_FILE = os.path.join(OUTPUT_FOLDER, \"idf.tsv\")\n",
    "TFIDF_FILE = os.path.join(OUTPUT_FOLDER, \"tfidf.tsv\")\n",
    "ANTI_DICT_FILE = os.path.join(OUTPUT_FOLDER, \"anti_dictionnaire.txt\")\n",
    "\n",
    "# Créer le dossier de sortie s'il n'existe pas\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Configuration pour pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "# Ignorer certains warnings de BeautifulSoup si nécessaire\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print(f\"Dossier des données (BULLETINS): {DATA_FOLDER}\")\n",
    "print(f\"Dossier de sortie: {OUTPUT_FOLDER}\")\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72676ecf2a38b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:17.306860Z",
     "start_time": "2025-03-26T22:08:12.546556Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## 2. TD2 - Chargement et Structuration du Corpus\n",
    "\n",
    "# ### 2.1. Instanciation du Parser\n",
    "#\n",
    "# Nous utilisons `BS4Parser` qui hérite de `FileProcessClient` pour lire et traiter les fichiers HTML.\n",
    "\n",
    "# +\n",
    "# Instancier le parser spécifique pour les fichiers HTML ADIT\n",
    "html_parser = BS4Parser()\n",
    "print(\"Parser BS4Parser instancié.\")\n",
    "# -\n",
    "\n",
    "# ### 2.2. Chargement des Documents depuis le Dossier\n",
    "#\n",
    "# `Corpus.from_folder` utilise le `BS4Parser` pour traiter tous les fichiers `.htm` dans le dossier spécifié.\n",
    "\n",
    "# +\n",
    "print(f\"Chargement des documents depuis {DATA_FOLDER}...\")\n",
    "# Utiliser Corpus.from_folder avec le parser\n",
    "# Pas de limite par défaut, charge tous les fichiers\n",
    "try:\n",
    "    corpus = Corpus.from_folder(html_parser, DATA_FOLDER)\n",
    "    print(f\"Chargement terminé. {len(corpus.documents)} documents ont été chargés et parsés.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERREUR: Le dossier '{DATA_FOLDER}' n'a pas été trouvé.\")\n",
    "    print(\"Vérifiez que le chemin est correct et que les données sont présentes.\")\n",
    "    # Stopper l'exécution ou gérer l'erreur autrement\n",
    "    corpus = None\n",
    "except TypeError as e:\n",
    "    print(f\"ERREUR: Problème de type lors du chargement: {e}\")\n",
    "    corpus = None\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR inattendue lors du chargement: {e}\")\n",
    "    corpus = None\n",
    "\n",
    "# Afficher un exemple de document chargé (si le chargement a réussi)\n",
    "if corpus and corpus.documents:\n",
    "    print(\"\\nExemple de document chargé (premier document) :\")\n",
    "    # Utilise la représentation Pydantic par défaut, qui est assez lisible\n",
    "    print(corpus.documents[0].model_dump(exclude_none=True))\n",
    "else:\n",
    "    print(\"\\nAucun document n'a pu être chargé. Vérifiez les erreurs précédentes.\")\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a9e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<index.transactions.corpus.Corpus at 0x18ee16b9f40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.save_to_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0770f66f028c2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:17.527358Z",
     "start_time": "2025-03-26T22:08:17.447890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde du corpus initial dans C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_initial.xml...\n",
      "Sauvegarde du corpus actuel (326 documents) dans C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_initial.xml...\n",
      "Corpus sauvegardé avec succès dans 'C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_initial.xml'.\n",
      "\n",
      "Contenu du début du fichier XML généré (C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_initial.xml):\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<corpus>\n",
      "  <bulletin>\n",
      "    <fichier>67068.htm</fichier>\n",
      "    <numero>258</numero>\n",
      "    <date>21/06/2011</date>\n",
      "    <rubrique>Focus</rubrique>\n",
      "    <titre>Physique : Mathias Fink, un bel exemple de chercheur qui innove</titre>\n",
      "    <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>\n",
      "    <contact>Institut Langevin &quot;Ondes et Images&quot; - Mathias Fink - email : mathias.fink@espci.fr - http://www.institut-langevin.espci.fr</contact>\n",
      "    <texte>Le 27 avril dernier, le CNRS décernait pour la première fois la Médaille de l'Innovation, dont Valérie Pécresse, ministre de l'Enseignement Supérieur et de la Recherche est à l'origine de la création. Le CNRS souhaite ainsi honorer des chercheurs et ingénieurs travaillant dans des établissements publics de recherche, des universités, des grandes écoles mais aussi des industriels qui développent des innovations marquantes. Pour cette première édition, cette nouvelle distinction a été attribuée à trois chercheurs réputés : l'économiste Esther Duflo, le roboticien François Pierrot et le physicien Mathias Fink. Directeur de l'Institut Langevin &quot;Ondes et Images&quot;, créé en janvier 2009 au sein de l'Ecole de Physique et de Chimie Industrielles de la Ville de Paris (ESPCI), Mathias Fink est un remarquable exemple de ces chercheurs qui innovent. Les travaux de son équipe ont en effet abouti à la création de quatre start-ups, qui totalisent 230 personnes, dans des domaines aussi variés que la médecine, les télécommunications, le multimédia ou encore les objets tactiles. &quot;J'aime transformer des idées de physique très fondamentale en produits innovants&quot;, précise d'emblée Mathias Fink. Mais pour y parvenir, il fallait trouver le &quot;terrain&quot; propice. Et c'est à la fin des années 1980, à l'occasion d'une rencontre avec Georges Charpak, le prix Nobel de Physique 1992, qu'il va le découvrir, au coeur de la Montagne Sainte Geneviève, en plein Paris. Alors physicien au sein d'un des plus grands laboratoires français de physique du solide, Mathias Fink souhaite faire de l'innovation autour du concept de renversement du temps. De la &quot;belle physique&quot; comme la qualifient les connaisseurs, qui plus est qui intéresse quatre grands industriels du secteur aéronautique (Dassault, Aerospatial, Snecma, Turboméca), prêts à financer des travaux. Mais à cette époque, le milieu de la recherche est encore peu enclin à travailler avec l'industrie, d'autant plus si celle-ci est &quot;militaro-industrielle&quot;. Aussi Mathias Fink se retrouve isolé. Georges Charpak lui propose alors de rencontrer Pierre-Gilles de Gennes, alors directeur de l'ESPCI, et Jacques Lewiner, le directeur scientifique. &quot;C'est un endroit sympathique&quot;, lui précise Georges Charpak. &quot;Je les ai rencontré. L'endroit était en effet très sympathique. Ils m'ont alors dit : vous voulez Innovez ? Alors venez&quot;, résume Mathias Fink qui ajoute : &quot;cela a été la chance de ma carrière&quot;. Vous êtes chercheur : amusez-vous C'est ainsi que dès 1990, ce physicien crée le Laboratoire Ondes et Acoustique, dans une école qu'il qualifie d'&quot;unique&quot;. &quot;Innover est particulièrement bien vu à l'ESPCI, et l'on vous donne le feu vert du moment que l'idée proposée est très originale&quot;, précise-t-il. Autre particularité de cette école vraiment pas comme les autres Grandes Ecoles, la pluridisciplinarité qui y règne. Ne cherchez pas, vous n'y trouverez pas comme ailleurs un département de physique, un département de chimie et un département de biologie. &quot;Ici, on vous dit dès le départ : vous êtes chercheur, amusez-vous&quot;, souligne-t-il avec une pointe d'humour. Et c'est en s'amusant que lui et son équipe ont développé les fameux miroirs à retournement temporel qui permettent d'échantillonner et d'enregistrer un champ acoustique incident puis de le réémettre dans une chronologie inversée. Mathias Fink et ses collaborateurs se sont rendus compte en effet que faire revivre à une onde sa vie passée permettait de focaliser cette onde à sa source d'une façon très efficace. Ils commencèrent alors à travailler d'abord sur les ultrasons, puis sur les ondes sismiques et les micro-ondes. Cette équipe aurait pu se limiter à publier d'excellents papiers dans des publications réputées comme Physical Review. Mais ces chercheurs ont compris très vite qu'au-delà de cette &quot;belle physique&quot;, il y avait des applications potentielles. Ainsi le renversement du temps permettait de brûler une tumeur, mais aussi de détruire un composant électronique, ou encore de voir derrière un mur ou d'envoyer des informations à un endroit précis dans une pièce. &quot;Progressivement, nous avons donc développé un certain nombre d'instruments originaux qui ont fini par déboucher sur la création de plusieurs start-ups&quot;, indique-t-il. A partir du concept de renversement du temps, Mathias Fink et son équipe ont découvert qu'il était possible de créer des images d'une autre façon. Aussi sont-ils parvenus à fabriquer des imageurs du corps humain grâce auxquels il est possible d'obtenir 10.000 images par seconde du corps humain. &quot;Nous avons pu alors découvrir que le corps humain était parcouru d'ondes que jamais personne n'avait observé jusqu'alors&quot;, s'enthousiasme-t-il. La pluridisciplinarité, clé de la réussite de l'Institut Langevin &quot;Ondes et Images&quot; Le renversement du temps aurait-il des effets sur l'âge de ceux qui le pratiquent ? Au-delà de la boutade, Mathias Fink, âgé aujourd'hui de 65 ans, pourrait le laisser croire, tant son enthousiasme reste intact. Ainsi, en 2009 a-t-il concrétisé le rapprochement de son laboratoire avec un autre laboratoire de l'ESPCI, celui d'Optique Physique, en créant l'Institut Langevin &quot;Ondes et Images&quot;, dont il est le directeur, Arnaud Tourin et Rémi Carminatti en étant les deux directeurs adjoints. Cette Unité Mixte de Recherche (CNRS/ESPCI ParisTech/UPMC/Université Paris-Diderot), qui compte une centaine de personnes, a pour coeur de métier la physique des ondes. Les recherches qui y sont menées s'étendent des concepts fondamentaux aux applications les plus poussées de l'imagerie multi-ondes (acousto-optique, photo-acoustique, élastographie par ultrasons ou IRM) aux techniques originales de focalisation (retournement temporel, filtre inverse, contrôle de front d'ondes), en passant par la création d'entreprises mettant en oeuvre ces nouvelles technologies dans les domaines du biomédical, des télécommunications, de la domotique, etc. &quot;L'aventure se poursuit, toujours dans la pluridisciplinarité, qui est la clé de notre réussite. Aussi faut-il impérativement la préserver&quot;, conclut-il.</texte>\n",
      "    <images/>\n",
      "  </bulletin>\n",
      "  <bulletin>\n",
      "    <fichier>67071.htm</fichier>\n"
     ]
    }
   ],
   "source": [
    "# ### 2.3. Sauvegarde du Corpus Initial en XML\n",
    "#\n",
    "# La méthode `save_to_xml` du `Corpus` sérialise chaque objet `Document` (qui hérite de `XMLBaseModel`) en XML et les regroupe sous une balise racine `<Corpus>`.\n",
    "\n",
    "# +\n",
    "if corpus and corpus.documents:\n",
    "    print(f\"\\nSauvegarde du corpus initial dans {XML_INITIAL_FILE}...\")\n",
    "    corpus.save_to_xml(XML_INITIAL_FILE, root_tag=\"corpus\") # TD demande <corpus>\n",
    "\n",
    "    # Note importante sur la structure XML générée :\n",
    "    # Par défaut, XMLBaseModel utilise le nom de la classe comme balise pour chaque document.\n",
    "    # Ici, ce sera <Document>. Le TD demandait <bulletin>.\n",
    "    # Pour obtenir <bulletin>, il faudrait soit:\n",
    "    # 1. Modifier la classe Document pour surcharger `model_dump_xml` et forcer le tag 'bulletin'.\n",
    "    #    Exemple (dans la classe Document):\n",
    "    #    def model_dump_xml(self, tag: Optional[str] = None) -> ET.Element:\n",
    "    #        return super().model_dump_xml(tag=\"bulletin\")\n",
    "    # 2. Modifier la méthode `Corpus.save_to_xml` pour passer tag=\"bulletin\" à doc.model_dump_xml().\n",
    "    # Pour ce notebook, nous utilisons le code tel quel et générons des balises <Document>.\n",
    "\n",
    "    print(f\"\\nContenu du début du fichier XML généré ({XML_INITIAL_FILE}):\")\n",
    "    try:\n",
    "        with open(XML_INITIAL_FILE, 'r', encoding='utf-8') as f:\n",
    "            for _ in range(15): # Afficher les 15 premières lignes\n",
    "                line = f.readline()\n",
    "                if not line: break\n",
    "                print(line, end='')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le fichier {XML_INITIAL_FILE} n'a pas été trouvé après tentative de sauvegarde.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSauvegarde XML annulée car aucun document n'a été chargé.\")\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f45067013b2bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:17.542361Z",
     "start_time": "2025-03-26T22:08:17.536867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciation de CorpusTFIDFCalculator...\n",
      "CorpusTFIDFCalculator instancié avec succès.\n"
     ]
    }
   ],
   "source": [
    "# ## 3. TD3 - Calcul TF-IDF et Filtrage\n",
    "\n",
    "# ### 3.1. Choix de l'Unité Documentaire\n",
    "#\n",
    "# Le TD demande de réfléchir au choix de l'unité documentaire (bulletin entier vs article).\n",
    "#\n",
    "# **Notre approche actuelle :**\n",
    "# *   Le `BS4Parser` crée un objet `Document` pour chaque fichier `.htm`. Chaque fichier semble correspondre à un *article* ou une *page* spécifique d'un bulletin.\n",
    "# *   Le `Corpus` contient une liste de ces objets `Document`.\n",
    "# *   Le `CorpusTFIDFCalculator` travaille sur cette liste de `Document`.\n",
    "#\n",
    "# **Conclusion :** L'unité documentaire implicitement utilisée par notre code est **l'article individuel** (représenté par un objet `Document` et identifié par son nom de fichier `fichier`). Le TF est calculé par article, et l'IDF est basé sur le nombre d'articles contenant un mot donné.\n",
    "\n",
    "# ### 3.2. Instanciation du Calculateur TF-IDF\n",
    "#\n",
    "# Nous créons une instance de `CorpusTFIDFCalculator` en lui passant notre `Corpus`.\n",
    "\n",
    "# +\n",
    "if corpus and corpus.documents:\n",
    "    print(\"Instanciation de CorpusTFIDFCalculator...\")\n",
    "    try:\n",
    "        # 'fichier' est le champ utilisé pour l'ID du document dans la classe Document\n",
    "        tfidf_calculator = CorpusTFIDFCalculator(corpus, doc_id_field='fichier')\n",
    "        print(\"CorpusTFIDFCalculator instancié avec succès.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ERREUR lors de l'instanciation du calculateur TF-IDF: {e}\")\n",
    "        tfidf_calculator = None\n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR inattendue lors de l'instanciation: {e}\")\n",
    "        tfidf_calculator = None\n",
    "else:\n",
    "    print(\"\\nImpossible d'instancier CorpusTFIDFCalculator car le corpus n'est pas chargé.\")\n",
    "    tfidf_calculator = None\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54524089d0c0a591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:17.779361Z",
     "start_time": "2025-03-26T22:08:17.552872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exécution de la segmentation (CorpusClient.segmente)...\n",
      "\n",
      "Segmentation terminée. 166183 paires (token, document_id) trouvées.\n",
      "Aperçu du DataFrame de segmentation :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>document_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>physique</td>\n",
       "      <td>67068.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathias</td>\n",
       "      <td>67068.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fink</td>\n",
       "      <td>67068.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un</td>\n",
       "      <td>67068.htm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bel</td>\n",
       "      <td>67068.htm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token document_id\n",
       "0  physique   67068.htm\n",
       "1   mathias   67068.htm\n",
       "2      fink   67068.htm\n",
       "3        un   67068.htm\n",
       "4       bel   67068.htm"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde de la segmentation dans C:\\Users\\Raphael\\Documents\\TD02\\output\\segmentation.tsv...\n",
      "Sauvegarde terminée.\n",
      "\n",
      "Contenu du début du fichier C:\\Users\\Raphael\\Documents\\TD02\\output\\segmentation.tsv:\n",
      "physique\t67068.htm\n",
      "mathias\t67068.htm\n",
      "fink\t67068.htm\n",
      "un\t67068.htm\n",
      "bel\t67068.htm\n",
      "exemple\t67068.htm\n",
      "de\t67068.htm\n",
      "chercheur\t67068.htm\n",
      "qui\t67068.htm\n",
      "innove\t67068.htm\n"
     ]
    }
   ],
   "source": [
    "# ### 3.3. Segmentation (Équivalent `segmente.py`)\n",
    "#\n",
    "# La méthode `segmente()` du `Corpus` extrait tous les tokens (`mot`, `document_id`) du corpus. Le TD3 demandait un script `segmente.py` produisant un fichier tabulé. Nous allons générer un DataFrame puis l'enregistrer dans ce format.\n",
    "\n",
    "# +\n",
    "if corpus and corpus.documents:\n",
    "    print(\"\\nExécution de la segmentation (Corpus.segmente)...\")\n",
    "    segmentation_df = corpus.segmente()\n",
    "\n",
    "    print(f\"\\nSegmentation terminée. {len(segmentation_df)} paires (token, document_id) trouvées.\")\n",
    "    print(\"Aperçu du DataFrame de segmentation :\")\n",
    "    display(segmentation_df.head())\n",
    "\n",
    "    # Sauvegarde au format TSV (comme demandé pour segmente.py)\n",
    "    print(f\"\\nSauvegarde de la segmentation dans {SEGMENTATION_FILE}...\")\n",
    "    try:\n",
    "        # Pas d'index, pas d'en-tête, séparateur tabulation\n",
    "        segmentation_df.to_csv(SEGMENTATION_FILE, sep='\\t', index=False, header=False, encoding='utf-8')\n",
    "        print(\"Sauvegarde terminée.\")\n",
    "\n",
    "        # Afficher le début du fichier généré\n",
    "        print(f\"\\nContenu du début du fichier {SEGMENTATION_FILE}:\")\n",
    "        try:\n",
    "            with open(SEGMENTATION_FILE, 'r', encoding='utf-8') as f:\n",
    "                for _ in range(10):\n",
    "                    line = f.readline()\n",
    "                    if not line: break\n",
    "                    print(line, end='')\n",
    "        except FileNotFoundError:\n",
    "             print(f\"Erreur: Le fichier {SEGMENTATION_FILE} n'a pas été trouvé après tentative de sauvegarde.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde de la segmentation: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSegmentation annulée car le corpus n'est pas chargé.\")\n",
    "    segmentation_df = pd.DataFrame(columns=['token', 'document_id']) # DataFrame vide\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d600462f55e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:18.222368Z",
     "start_time": "2025-03-26T22:08:17.798922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcul de TF (Term Frequency)...\n",
      "Recalcul de TF...\n",
      "Calcul TF terminé. 80673 entrées TF générées.\n",
      "Aperçu du DataFrame TF :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>mot</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>physique</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>mathias</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>fink</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>un</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>bel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id       mot  tf\n",
       "0   67068.htm  physique  10\n",
       "1   67068.htm   mathias  10\n",
       "2   67068.htm      fink  10\n",
       "3   67068.htm        un  13\n",
       "4   67068.htm       bel   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde de TF dans C:\\Users\\Raphael\\Documents\\TD02\\output\\tf.tsv...\n",
      "Sauvegarde TF terminée.\n",
      "\n",
      "Calcul de IDF (Inverse Document Frequency)...\n",
      "Recalcul de IDF...\n",
      "Calcul IDF terminé. 14486 mots uniques avec IDF calculé.\n",
      "Aperçu du DataFrame IDF :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mot</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>l</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>à</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>de</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>et</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>la</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mot       idf\n",
       "7427    l  0.000000\n",
       "14107   à  0.000000\n",
       "3720   de  0.000000\n",
       "5069   et  0.000000\n",
       "7428   la  0.001334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde de IDF dans C:\\Users\\Raphael\\Documents\\TD02\\output\\idf.tsv...\n",
      "Sauvegarde IDF terminée.\n",
      "\n",
      "Calcul de TF-IDF...\n",
      "Recalcul de TF-IDF...\n",
      "Calcul TF-IDF terminé. 80673 entrées TF-IDF générées.\n",
      "Aperçu du DataFrame TF-IDF (trié par score décroissant pour le premier document):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raphael\\Documents\\TD02\\index\\clients\\corpus_client.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tfidf_df['idf'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>mot</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>fink</td>\n",
       "      <td>25.132176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>mathias</td>\n",
       "      <td>25.132176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>ondes</td>\n",
       "      <td>14.718249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>physique</td>\n",
       "      <td>11.514898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>renversement</td>\n",
       "      <td>10.052870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>espci</td>\n",
       "      <td>9.071238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>charpak</td>\n",
       "      <td>7.539653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>images</td>\n",
       "      <td>6.685632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>langevin</td>\n",
       "      <td>6.636563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>67068.htm</td>\n",
       "      <td>vous</td>\n",
       "      <td>6.584172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document_id           mot     tf_idf\n",
       "2     67068.htm          fink  25.132176\n",
       "1     67068.htm       mathias  25.132176\n",
       "73    67068.htm         ondes  14.718249\n",
       "0     67068.htm      physique  11.514898\n",
       "162   67068.htm  renversement  10.052870\n",
       "86    67068.htm         espci   9.071238\n",
       "140   67068.htm       charpak   7.539653\n",
       "74    67068.htm        images   6.685632\n",
       "72    67068.htm      langevin   6.636563\n",
       "210   67068.htm          vous   6.584172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde de TF-IDF dans C:\\Users\\Raphael\\Documents\\TD02\\output\\tfidf.tsv...\n",
      "Sauvegarde TF-IDF terminée.\n"
     ]
    }
   ],
   "source": [
    "# +\n",
    "if tfidf_calculator:\n",
    "    # --- Calcul TF ---\n",
    "    print(\"\\nCalcul de TF (Term Frequency)...\")\n",
    "    tf_df = tfidf_calculator.calculate_tf()\n",
    "    print(\"Aperçu du DataFrame TF :\")\n",
    "    display(tf_df.head())\n",
    "    # Sauvegarde optionnelle du TF (format demandé par TD3)\n",
    "    if not tf_df.empty:\n",
    "        print(f\"Sauvegarde de TF dans {TF_FILE}...\")\n",
    "        try:\n",
    "            # Colonnes: identifiant_du_document, mot, tf\n",
    "            tf_df.to_csv(TF_FILE, sep='\\t', index=False, header=True, encoding='utf-8')\n",
    "            print(\"Sauvegarde TF terminée.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la sauvegarde de TF: {e}\")\n",
    "    else:\n",
    "        print(\"DataFrame TF est vide, sauvegarde annulée.\")\n",
    "\n",
    "    # --- Calcul IDF ---\n",
    "    print(\"\\nCalcul de IDF (Inverse Document Frequency)...\")\n",
    "    idf_df = tfidf_calculator.calculate_idf()\n",
    "    print(\"Aperçu du DataFrame IDF :\")\n",
    "    # Afficher les mots avec IDF le plus bas (les plus fréquents/communs)\n",
    "    display(idf_df.sort_values(by='idf').head())\n",
    "    # Afficher les mots avec IDF le plus haut (les plus rares/discriminants)\n",
    "    #display(idf_df.sort_values(by='idf', ascending=False).head())\n",
    "\n",
    "    # Sauvegarde optionnelle de l'IDF (format demandé par TD3)\n",
    "    if not idf_df.empty:\n",
    "        print(f\"Sauvegarde de IDF dans {IDF_FILE}...\")\n",
    "        try:\n",
    "            # Colonnes: mot, idf\n",
    "            idf_df.to_csv(IDF_FILE, sep='\\t', index=False, header=True, encoding='utf-8')\n",
    "            print(\"Sauvegarde IDF terminée.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la sauvegarde de IDF: {e}\")\n",
    "    else:\n",
    "        print(\"DataFrame IDF est vide, sauvegarde annulée.\")\n",
    "\n",
    "    # --- Calcul TF-IDF ---\n",
    "    print(\"\\nCalcul de TF-IDF...\")\n",
    "    tfidf_df = tfidf_calculator.calculate_tfidf()\n",
    "    print(\"Aperçu du DataFrame TF-IDF (trié par score décroissant pour le premier document):\")\n",
    "    if not tfidf_df.empty:\n",
    "        first_doc_id = tfidf_df['document_id'].iloc[0]\n",
    "        display(tfidf_df[tfidf_df['document_id'] == first_doc_id].sort_values(by='tf_idf', ascending=False).head(10))\n",
    "    else:\n",
    "        display(tfidf_df.head()) # Affichera un DataFrame vide avec les bonnes colonnes\n",
    "\n",
    "    # Sauvegarde optionnelle du TF-IDF (format demandé par TD3)\n",
    "    if not tfidf_df.empty:\n",
    "        print(f\"Sauvegarde de TF-IDF dans {TFIDF_FILE}...\")\n",
    "        try:\n",
    "            # Colonnes: identifiant_du_document, mot, tf_idf\n",
    "            tfidf_df.to_csv(TFIDF_FILE, sep='\\t', index=False, header=True, encoding='utf-8')\n",
    "            print(\"Sauvegarde TF-IDF terminée.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la sauvegarde de TF-IDF: {e}\")\n",
    "    else:\n",
    "        print(\"DataFrame TF-IDF est vide, sauvegarde annulée.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nCalculs TF/IDF/TF-IDF annulés car le calculateur n'a pas été instancié.\")\n",
    "    tf_df = pd.DataFrame(columns=['document_id', 'mot', 'tf'])\n",
    "    idf_df = pd.DataFrame(columns=['mot', 'idf'])\n",
    "    tfidf_df = pd.DataFrame(columns=['document_id', 'mot', 'tf_idf'])\n",
    "\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddaa5c61c76b8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:18.258516Z",
     "start_time": "2025-03-26T22:08:18.245227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération de l'anti-dictionnaire avec seuil IDF <= 0.05...\n",
      "Nombre de mots candidats pour l'anti-dictionnaire: 16\n",
      "Exemples de mots (les 20 avec le plus bas IDF parmi les candidats):\n",
      "        mot       idf\n",
      "3720     de  0.000000\n",
      "7427      l  0.000000\n",
      "5069     et  0.000000\n",
      "14107     à  0.000000\n",
      "7428     la  0.001334\n",
      "7564     le  0.002673\n",
      "4741     en  0.005362\n",
      "3787    des  0.005362\n",
      "7601    les  0.005362\n",
      "3683      d  0.008068\n",
      "10211  pour  0.021856\n",
      "4172     du  0.023259\n",
      "13529   une  0.031775\n",
      "13527    un  0.033211\n",
      "10897   qui  0.043396\n",
      "3696   dans  0.049325\n",
      "Anti-dictionnaire sauvegardé dans 'C:\\Users\\Raphael\\Documents\\TD02\\output\\anti_dictionnaire.txt'\n",
      "\n",
      "Chemin du fichier généré : C:\\Users\\Raphael\\Documents\\TD02\\output\\anti_dictionnaire.txt\n",
      "Contenu du début du fichier C:\\Users\\Raphael\\Documents\\TD02\\output\\anti_dictionnaire.txt:\n",
      "d\t\"\"\n",
      "dans\t\"\"\n",
      "de\t\"\"\n",
      "des\t\"\"\n",
      "du\t\"\"\n",
      "en\t\"\"\n",
      "et\t\"\"\n",
      "l\t\"\"\n",
      "la\t\"\"\n",
      "le\t\"\"\n",
      "les\t\"\"\n",
      "pour\t\"\"\n",
      "qui\t\"\"\n",
      "un\t\"\"\n",
      "une\t\"\"\n",
      "à\t\"\"\n"
     ]
    }
   ],
   "source": [
    "# ### 3.4. Calcul TF, IDF, TF-IDF\n",
    "#\n",
    "# Nous utilisons les méthodes du `CorpusTFIDFCalculator`. Les résultats sont mis en cache dans l'instance du calculateur.\n",
    "\n",
    "\n",
    "# ### 3.5. Génération de l'Anti-dictionnaire\n",
    "#\n",
    "# L'anti-dictionnaire contient les mots considérés comme non significatifs, basé sur un seuil IDF bas. Un IDF faible signifie que le mot apparaît dans de nombreux documents.\n",
    "\n",
    "# +\n",
    "if tfidf_calculator:\n",
    "    # Choix du seuil IDF\n",
    "    # Un seuil bas inclura plus de mots (ceux présents dans beaucoup de documents).\n",
    "    # Le TD suggère 0.1, mais on peut expérimenter.\n",
    "    IDF_THRESHOLD = 0.05 # Essayons un seuil un peu plus bas pour capturer les mots très communs\n",
    "\n",
    "    # La méthode generate_anti_dict utilise le idf_df calculé précédemment\n",
    "    generated_anti_dict_path = tfidf_calculator.generate_anti_dict(\n",
    "        idf_threshold=IDF_THRESHOLD,\n",
    "        output_file=ANTI_DICT_FILE\n",
    "    )\n",
    "\n",
    "    print(f\"\\nChemin du fichier généré : {generated_anti_dict_path}\")\n",
    "\n",
    "    # Afficher le début du fichier anti-dictionnaire\n",
    "    print(f\"Contenu du début du fichier {ANTI_DICT_FILE}:\")\n",
    "    try:\n",
    "        with open(ANTI_DICT_FILE, 'r', encoding='utf-8') as f:\n",
    "            for _ in range(20): # Afficher les 20 premiers mots\n",
    "                line = f.readline()\n",
    "                if not line: break\n",
    "                print(line, end='')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le fichier {ANTI_DICT_FILE} n'a pas été trouvé après tentative de génération.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nGénération de l'anti-dictionnaire annulée car le calculateur n'a pas été instancié.\")\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71df581253f3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:18.514586Z",
     "start_time": "2025-03-26T22:08:18.306249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Application des substitutions depuis C:\\Users\\Raphael\\Documents\\TD02\\output\\anti_dictionnaire.txt sur le corpus en mémoire...\n",
      "Application des substitutions depuis C:\\Users\\Raphael\\Documents\\TD02\\output\\anti_dictionnaire.txt sur 326 documents...\n",
      "  ... 100/326 documents traités.\n",
      "  ... 200/326 documents traités.\n",
      "  ... 300/326 documents traités.\n",
      "  ... 326/326 documents traités.\n",
      "Substitutions appliquées. 326 documents ont été modifiés.\n",
      "Le cache de la propriété 'corps' a été invalidé pour les documents modifiés.\n",
      "\n",
      "Exemple de document après substitutions (premier document) :\n",
      "Nouveau 'corps' recalculé :\n",
      "Physique : Mathias Fink, bel exemple chercheur innove\n",
      "27 avril dernier, CNRS décernait première fois Médaille Innovation, dont Valérie Pécresse, ministre Enseignement Supérieur Recherche est origine création. CNRS souhaite ainsi honorer chercheurs ingénieurs travaillant établissements publics recherche, universités, grandes écoles mais aussi industriels développent innovations marquantes. cette première édition, cette nouvelle distinction a été attribuée trois chercheurs réputés : économiste Est...\n"
     ]
    }
   ],
   "source": [
    "# ### 3.6. Application des Substitutions (Filtrage)\n",
    "#\n",
    "# La méthode `apply_substitutions` du `Corpus` lit l'anti-dictionnaire et modifie *en mémoire* les champs texte (`titre`, `texte` comme défini dans `corps_fields` de `Document`) des objets `Document`. Elle invalide aussi le cache de la propriété `corps`.\n",
    "\n",
    "# +\n",
    "if corpus and os.path.exists(ANTI_DICT_FILE):\n",
    "    print(f\"\\nApplication des substitutions depuis {ANTI_DICT_FILE} sur le corpus en mémoire...\")\n",
    "\n",
    "    # Attention: Cette opération modifie les objets Document dans corpus.documents\n",
    "    corpus.apply_substitutions(ANTI_DICT_FILE)\n",
    "\n",
    "    # Vérification (Optionnel) : Afficher le 'corps' d'un document avant et après\n",
    "    # Note : Pour que cela fonctionne, il faudrait garder une copie du document original\n",
    "    # ou recharger un document spécifique.\n",
    "    # Ici, on peut juste ré-afficher un document pour voir s'il semble modifié.\n",
    "    if corpus.documents:\n",
    "        print(\"\\nExemple de document après substitutions (premier document) :\")\n",
    "        # Afficher le corps recalculé (le cache a été invalidé si modifié)\n",
    "        print(\"Nouveau 'corps' recalculé :\")\n",
    "        print(corpus.documents[0].corps[:500] + \"...\") # Afficher les 500 premiers caractères\n",
    "\n",
    "elif not corpus:\n",
    "    print(\"\\nApplication des substitutions annulée car le corpus n'est pas chargé.\")\n",
    "elif not os.path.exists(ANTI_DICT_FILE):\n",
    "    print(f\"\\nApplication des substitutions annulée car le fichier {ANTI_DICT_FILE} n'existe pas.\")\n",
    "\n",
    "# -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed55416911ed108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T22:08:18.567287Z",
     "start_time": "2025-03-26T22:08:18.516334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sauvegarde du corpus filtré (après substitutions) dans C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_filtre.xml...\n",
      "Sauvegarde du corpus actuel (326 documents) dans C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_filtre.xml...\n",
      "Corpus sauvegardé avec succès dans 'C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_filtre.xml'.\n",
      "\n",
      "Corpus filtré sauvegardé. Vérifiez le fichier C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_filtre.xml.\n",
      "\n",
      "Contenu du début du fichier XML filtré (C:\\Users\\Raphael\\Documents\\TD02\\output\\corpus_filtre.xml):\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<corpus>\n",
      "  <bulletin>\n",
      "    <fichier>67068.htm</fichier>\n",
      "    <numero>258</numero>\n",
      "    <date>21/06/2011</date>\n",
      "    <rubrique>Focus</rubrique>\n",
      "    <titre>Physique : Mathias Fink, bel exemple chercheur innove</titre>\n",
      "    <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>\n",
      "    <contact>Institut Langevin &quot;Ondes et Images&quot; - Mathias Fink - email : mathias.fink@espci.fr - http://www.institut-langevin.espci.fr</contact>\n",
      "    <texte>27 avril dernier, CNRS décernait première fois Médaille Innovation, dont Valérie Pécresse, ministre Enseignement Supérieur Recherche est origine création. CNRS souhaite ainsi honorer chercheurs ingénieurs travaillant établissements publics recherche, universités, grandes écoles mais aussi industriels développent innovations marquantes. cette première édition, cette nouvelle distinction a été attribuée trois chercheurs réputés : économiste Esther Duflo, roboticien François Pierrot physicien Mathias Fink. Directeur Institut Langevin &quot;Ondes Images&quot;, créé janvier 2009 au sein Ecole Physique Chimie Industrielles Ville Paris (ESPCI), Mathias Fink est remarquable exemple ces chercheurs innovent. travaux son équipe ont effet abouti création quatre start-ups, totalisent 230 personnes, domaines aussi variés que médecine, télécommunications, multimédia ou encore objets tactiles. &quot;J aime transformer idées physique très fondamentale produits innovants&quot;, précise emblée Mathias Fink. Mais y parvenir, il fallait trouver &quot;terrain&quot; propice. c est fin années 1980, occasion rencontre avec Georges Charpak, prix Nobel Physique 1992, qu il va découvrir, au coeur Montagne Sainte Geneviève, plein Paris. Alors physicien au sein plus grands laboratoires français physique solide, Mathias Fink souhaite faire innovation autour concept renversement temps. &quot;belle physique&quot; comme qualifient connaisseurs, plus est intéresse quatre grands industriels secteur aéronautique (Dassault, Aerospatial, Snecma, Turboméca), prêts financer travaux. Mais cette époque, milieu recherche est encore peu enclin travailler avec industrie, autant plus si celle-ci est &quot;militaro-industrielle&quot;. Aussi Mathias Fink se retrouve isolé. Georges Charpak lui propose alors rencontrer Pierre-Gilles Gennes, alors directeur ESPCI, Jacques Lewiner, directeur scientifique. &quot;C est endroit sympathique&quot;, lui précise Georges Charpak. &quot;Je ai rencontré. endroit était effet très sympathique. Ils m ont alors dit : vous voulez Innovez ? Alors venez&quot;, résume Mathias Fink ajoute : &quot;cela a été chance ma carrière&quot;. Vous êtes chercheur : amusez-vous C est ainsi que dès 1990, ce physicien crée Laboratoire Ondes Acoustique, école qu il qualifie &quot;unique&quot;. &quot;Innover est particulièrement bien vu ESPCI, on vous donne feu vert moment que idée proposée est très originale&quot;, précise-t-il. Autre particularité cette école vraiment pas comme autres Grandes Ecoles, pluridisciplinarité y règne. Ne cherchez pas, vous n y trouverez pas comme ailleurs département physique, département chimie département biologie. &quot;Ici, on vous dit dès départ : vous êtes chercheur, amusez-vous&quot;, souligne-t-il avec pointe humour. c est s amusant que lui son équipe ont développé fameux miroirs retournement temporel permettent échantillonner enregistrer champ acoustique incident puis réémettre chronologie inversée. Mathias Fink ses collaborateurs se sont rendus compte effet que faire revivre onde sa vie passée permettait focaliser cette onde sa source façon très efficace. Ils commencèrent alors travailler abord sur ultrasons, puis sur ondes sismiques micro-ondes. Cette équipe aurait pu se limiter publier excellents papiers publications réputées comme Physical Review. Mais ces chercheurs ont compris très vite qu au-delà cette &quot;belle physique&quot;, il y avait applications potentielles. Ainsi renversement temps permettait brûler tumeur, mais aussi détruire composant électronique, ou encore voir derrière mur ou envoyer informations endroit précis pièce. &quot;Progressivement, nous avons donc développé certain nombre instruments originaux ont fini par déboucher sur création plusieurs start-ups&quot;, indique-t-il. A partir concept renversement temps, Mathias Fink son équipe ont découvert qu il était possible créer images autre façon. Aussi sont-ils parvenus fabriquer imageurs corps humain grâce auxquels il est possible obtenir 10.000 images par seconde corps humain. &quot;Nous avons pu alors découvrir que corps humain était parcouru ondes que jamais personne n avait observé jusqu alors&quot;, s enthousiasme-t-il. pluridisciplinarité, clé réussite Institut Langevin &quot;Ondes Images&quot; renversement temps aurait-il effets sur âge ceux pratiquent ? Au-delà boutade, Mathias Fink, âgé aujourd hui 65 ans, pourrait laisser croire, tant son enthousiasme reste intact. Ainsi, 2009 a-t-il concrétisé rapprochement son laboratoire avec autre laboratoire ESPCI, celui Optique Physique, créant Institut Langevin &quot;Ondes Images&quot;, dont il est directeur, Arnaud Tourin Rémi Carminatti étant deux directeurs adjoints. Cette Unité Mixte Recherche (CNRS/ESPCI ParisTech/UPMC/Université Paris-Diderot), compte centaine personnes, a coeur métier physique ondes. recherches y sont menées s étendent concepts fondamentaux aux applications plus poussées imagerie multi-ondes (acousto-optique, photo-acoustique, élastographie par ultrasons ou IRM) aux techniques originales focalisation (retournement temporel, filtre inverse, contrôle front ondes), passant par création entreprises mettant oeuvre ces nouvelles technologies domaines biomédical, télécommunications, domotique, etc. &quot; aventure se poursuit, toujours pluridisciplinarité, est clé notre réussite. Aussi faut-il impérativement préserver&quot;, conclut-il.</texte>\n",
      "    <images/>\n",
      "  </bulletin>\n",
      "  <bulletin>\n",
      "    <fichier>67071.htm</fichier>\n",
      "    <numero>258</numero>\n",
      "    <date>21/06/2011</date>\n",
      "    <rubrique>Actualité Innovation</rubrique>\n",
      "    <titre>Recherche environnement : AllEnvi publie son premier rapport</titre>\n",
      "    <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### 3.7. Sauvegarde du Corpus Filtré en XML\n",
    "#\n",
    "# Nous sauvegardons à nouveau le corpus, mais cette fois les objets `Document` ont été modifiés en mémoire par `apply_substitutions`.\n",
    "\n",
    "# +\n",
    "if corpus and corpus.documents:\n",
    "    print(f\"\\nSauvegarde du corpus filtré (après substitutions) dans {XML_FILTRE_FILE}...\")\n",
    "    corpus.save_to_xml(XML_FILTRE_FILE, root_tag=\"corpus\") # TD demande <corpus>\n",
    "\n",
    "    print(f\"\\nCorpus filtré sauvegardé. Vérifiez le fichier {XML_FILTRE_FILE}.\")\n",
    "\n",
    "    # Afficher le début du fichier XML filtré\n",
    "    print(f\"\\nContenu du début du fichier XML filtré ({XML_FILTRE_FILE}):\")\n",
    "    try:\n",
    "        with open(XML_FILTRE_FILE, 'r', encoding='utf-8') as f:\n",
    "            for _ in range(20): # Afficher les 20 premières lignes\n",
    "                line = f.readline()\n",
    "                if not line: break\n",
    "                print(line, end='')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le fichier {XML_FILTRE_FILE} n'a pas été trouvé après tentative de sauvegarde.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSauvegarde du corpus filtré annulée car le corpus n'est pas chargé ou n'a pas été modifié.\")\n",
    "# -\n",
    "\n",
    "# ## 4. Conclusion\n",
    "#\n",
    "# Le processus est terminé.\n",
    "#\n",
    "# **Fichiers générés dans le dossier `output/` :**\n",
    "# *   `corpus_initial.xml`: Le corpus original structuré en XML.\n",
    "# *   `segmentation.tsv`: Liste des paires (token, document_id).\n",
    "# *   `tf.tsv`: Fréquence des termes par document.\n",
    "# *   `idf.tsv`: Inverse Document Frequency pour chaque terme unique.\n",
    "# *   `tfidf.tsv`: Score TF-IDF pour chaque terme dans chaque document.\n",
    "# *   `anti_dictionnaire.txt`: Liste des mots à supprimer (basée sur le seuil IDF).\n",
    "# *   `corpus_filtre.xml`: Le corpus après suppression des mots de l'anti-dictionnaire."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
