<?xml version="1.0" encoding="utf-8"?>
<corpus>
  <bulletins>
    <bulletin>
      <fichier>67068.htm</fichier>
      <numero>258</numero>
      <date>21/06/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Physique : Mathias Fink, un bel exemple de chercheur qui innove</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Institut Langevin &quot;Ondes et Images&quot; - Mathias Fink - email : mathias.fink@espci.fr - http://www.institut-langevin.espci.fr</contact>
      <texte>Le 27 avril dernier, le CNRS décernait pour la première fois la Médaille de l'Innovation, dont Valérie Pécresse, ministre de l'Enseignement Supérieur et de la Recherche est à l'origine de la création. Le CNRS souhaite ainsi honorer des chercheurs et ingénieurs travaillant dans des établissements publics de recherche, des universités, des grandes écoles mais aussi des industriels qui développent des innovations marquantes. Pour cette première édition, cette nouvelle distinction a été attribuée à trois chercheurs réputés : l'économiste Esther Duflo, le roboticien François Pierrot et le physicien Mathias Fink. Directeur de l'Institut Langevin &quot;Ondes et Images&quot;, créé en janvier 2009 au sein de l'Ecole de Physique et de Chimie Industrielles de la Ville de Paris (ESPCI), Mathias Fink est un remarquable exemple de ces chercheurs qui innovent. Les travaux de son équipe ont en effet abouti à la création de quatre start-ups, qui totalisent 230 personnes, dans des domaines aussi variés que la médecine, les télécommunications, le multimédia ou encore les objets tactiles. &quot;J'aime transformer des idées de physique très fondamentale en produits innovants&quot;, précise d'emblée Mathias Fink. Mais pour y parvenir, il fallait trouver le &quot;terrain&quot; propice. Et c'est à la fin des années 1980, à l'occasion d'une rencontre avec Georges Charpak, le prix Nobel de Physique 1992, qu'il va le découvrir, au coeur de la Montagne Sainte Geneviève, en plein Paris. Alors physicien au sein d'un des plus grands laboratoires français de physique du solide, Mathias Fink souhaite faire de l'innovation autour du concept de renversement du temps. De la &quot;belle physique&quot; comme la qualifient les connaisseurs, qui plus est qui intéresse quatre grands industriels du secteur aéronautique (Dassault, Aerospatial, Snecma, Turboméca), prêts à financer des travaux. Mais à cette époque, le milieu de la recherche est encore peu enclin à travailler avec l'industrie, d'autant plus si celle-ci est &quot;militaro-industrielle&quot;. Aussi Mathias Fink se retrouve isolé. Georges Charpak lui propose alors de rencontrer Pierre-Gilles de Gennes, alors directeur de l'ESPCI, et Jacques Lewiner, le directeur scientifique. &quot;C'est un endroit sympathique&quot;, lui précise Georges Charpak. &quot;Je les ai rencontré. L'endroit était en effet très sympathique. Ils m'ont alors dit : vous voulez Innovez ? Alors venez&quot;, résume Mathias Fink qui ajoute : &quot;cela a été la chance de ma carrière&quot;. Vous êtes chercheur : amusez-vous C'est ainsi que dès 1990, ce physicien crée le Laboratoire Ondes et Acoustique, dans une école qu'il qualifie d'&quot;unique&quot;. &quot;Innover est particulièrement bien vu à l'ESPCI, et l'on vous donne le feu vert du moment que l'idée proposée est très originale&quot;, précise-t-il. Autre particularité de cette école vraiment pas comme les autres Grandes Ecoles, la pluridisciplinarité qui y règne. Ne cherchez pas, vous n'y trouverez pas comme ailleurs un département de physique, un département de chimie et un département de biologie. &quot;Ici, on vous dit dès le départ : vous êtes chercheur, amusez-vous&quot;, souligne-t-il avec une pointe d'humour. Et c'est en s'amusant que lui et son équipe ont développé les fameux miroirs à retournement temporel qui permettent d'échantillonner et d'enregistrer un champ acoustique incident puis de le réémettre dans une chronologie inversée. Mathias Fink et ses collaborateurs se sont rendus compte en effet que faire revivre à une onde sa vie passée permettait de focaliser cette onde à sa source d'une façon très efficace. Ils commencèrent alors à travailler d'abord sur les ultrasons, puis sur les ondes sismiques et les micro-ondes. Cette équipe aurait pu se limiter à publier d'excellents papiers dans des publications réputées comme Physical Review. Mais ces chercheurs ont compris très vite qu'au-delà de cette &quot;belle physique&quot;, il y avait des applications potentielles. Ainsi le renversement du temps permettait de brûler une tumeur, mais aussi de détruire un composant électronique, ou encore de voir derrière un mur ou d'envoyer des informations à un endroit précis dans une pièce. &quot;Progressivement, nous avons donc développé un certain nombre d'instruments originaux qui ont fini par déboucher sur la création de plusieurs start-ups&quot;, indique-t-il. A partir du concept de renversement du temps, Mathias Fink et son équipe ont découvert qu'il était possible de créer des images d'une autre façon. Aussi sont-ils parvenus à fabriquer des imageurs du corps humain grâce auxquels il est possible d'obtenir 10.000 images par seconde du corps humain. &quot;Nous avons pu alors découvrir que le corps humain était parcouru d'ondes que jamais personne n'avait observé jusqu'alors&quot;, s'enthousiasme-t-il. La pluridisciplinarité, clé de la réussite de l'Institut Langevin &quot;Ondes et Images&quot; Le renversement du temps aurait-il des effets sur l'âge de ceux qui le pratiquent ? Au-delà de la boutade, Mathias Fink, âgé aujourd'hui de 65 ans, pourrait le laisser croire, tant son enthousiasme reste intact. Ainsi, en 2009 a-t-il concrétisé le rapprochement de son laboratoire avec un autre laboratoire de l'ESPCI, celui d'Optique Physique, en créant l'Institut Langevin &quot;Ondes et Images&quot;, dont il est le directeur, Arnaud Tourin et Rémi Carminatti en étant les deux directeurs adjoints. Cette Unité Mixte de Recherche (CNRS/ESPCI ParisTech/UPMC/Université Paris-Diderot), qui compte une centaine de personnes, a pour coeur de métier la physique des ondes. Les recherches qui y sont menées s'étendent des concepts fondamentaux aux applications les plus poussées de l'imagerie multi-ondes (acousto-optique, photo-acoustique, élastographie par ultrasons ou IRM) aux techniques originales de focalisation (retournement temporel, filtre inverse, contrôle de front d'ondes), en passant par la création d'entreprises mettant en oeuvre ces nouvelles technologies dans les domaines du biomédical, des télécommunications, de la domotique, etc. &quot;L'aventure se poursuit, toujours dans la pluridisciplinarité, qui est la clé de notre réussite. Aussi faut-il impérativement la préserver&quot;, conclut-il.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67071.htm</fichier>
      <numero>258</numero>
      <date>21/06/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Recherche pour l'environnement : AllEnvi publie son premier rapport</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>AllEnvi - http://www.allenvi.fr</contact>
      <texte>AllENVI, l'Alliance nationale de recherche pour l'Environnement, a été créée le 9 février 2010, à l'initiative de Valérie Pécresse, ministre de l'Enseignement supérieur et de la Recherche. &quot;L'environnement est un système complexe qui recouvre un champ très étendu, de l'agroécologie à l'aménagement des territoires, en passant par les sciences de la mer ou du climat. Biologie, écologie, physico-chimie, mathématiques appliquées, géographie, sciences économiques et sociales ... Toutes les disciplines sont mobilisées par les sciences environnementales&quot;, rappelle en introduction Roger Genet, Président d'AllEnvi et directeur général du Cemagref. D'où la nécessité pour mieux programmer et coordonner l'interdisciplinarité qui caractérise cette recherche de regrouper les principaux opérateurs de recherche dans le domaine de l'environnement au sein de cette Alliance nationale de recherche pour l'Environnement qui compte 12 membres fondateurs [1] Alimentation, Eau, Climat et Territoires constituent les quatre grands enjeux d'AllEnvi. De véritables défis à relever pour les décennies à venir puisqu'il s'agira notamment en matière d'alimentation de parvenir à nourrir 9 milliards d'individus à l'horizon 2050. Concernant l'eau, son accès devra être garanti au plan mondial, non seulement en qualité mais nécessairement en quantité. Autre défi de taille auquel l'humanité devra faire face, les changements climatiques et l'érosion de la biodiversité. Enfin, toutes les populations de la planète devront respecter un impératif, celui de la qualité environnementale des territoires. Au sein d'AllEnvi, le travail des chercheurs est organisé en 12 groupes thématiques, réunissant plus de 250 experts scientifiques : &quot;Agroécologie et Sol&quot;, &quot;Aliments et Alimentation&quot;, &quot;Biodiversité&quot;, &quot;Biologie des plantes&quot;, &quot;Climat (Evolution, Adaptation, Atténuation, Impacts)&quot;, &quot;Eau&quot;, &quot;Ecotechnologies et Chimie durable&quot;, &quot;Sciences de la mer et Ressources marines&quot;, &quot;Risques environnementaux, naturels et écotoxiques&quot;, &quot;Territoires et Ressources naturelles&quot;, &quot;Villes et Mobilités&quot;, &quot;Evaluation environnementale et Cycle de vie&quot;. &quot;Un nouvel élan a été initié&quot;, déclare le Président d'AllEnvi. &quot;Il revient maintenant à nos 15.000 scientifiques, chercheurs, ingénieurs et techniciens, d'identifier, concevoir, valider et déployer les solutions qui permettront de relever les défis de la transition écologique vers une croissante verte&quot;, conclut-il dans l'introduction du premier rapport publié par cette Alliance nationale de recherche pour l'Environnement. -- [1] BRGM, CEA, Cemagref, Cirad, CNRS, Ifremer, IFSTTAR, INRA, IRD, Conférence des Présidents d'Universités, Météo France, Muséum National d'Histoire Naturelle</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67383.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Une médaille de l'innovation qui récompense un roboticien qui ne cesse d'innover</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Lirmm - François Pierrot - email : francois.pierrot@lirmm.fr</contact>
      <texte>Le 27 avril dernier, le CNRS a décerné pour la première fois la Médaille de l'Innovation. Parmi les trois lauréats, François Pierrot, directeur de recherche au CNRS au sein du Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier, le LIRMM. Réputé mondialement, ce roboticien a notamment participé à la conception et au développement du robot parallèle le plus rapide du monde dont le brevet a été racheté par l'entreprise américaine leader dans le domaine des systèmes robotisés, Adept. Autant dire que contrairement à beaucoup de gens qui dissertent sur l'innovation, ce chercheur, lui, sait ce qu'est l'innovation puisqu'il la vit et la pratique au quotidien. Qui plus est, il en parle remarquablement bien. &quot;Pour innover, il faut évidemment des idées, c'est indispensable, mais aussi souvent beaucoup de chance. Or depuis le début de ma carrière, je n'ai cessé d'en avoir&quot;, déclare-t-il d'emblée. Il rappelle que la première chance de sa carrière professionnelle est d'avoir été recruté au CNRS &quot;qui me soutient depuis plus de vingt ans et m'accorde une très grande liberté dans mon travail, ce qui est important&quot;. Pour lui, l'innovation n'est pas un travail solitaire, bien au contraire. D'où la nécessité de disposer d'une équipe. Et sa seconde chance est d'avoir été recruté à Montpellier, une ville magnifique qui dispose d'un potentiel de recherche tout à fait exceptionnel et en particulier d'un laboratoire réputé mondialement, le LIRMM. &quot;Ce laboratoire exceptionnel renferme une équipe de robotique qui concentre de grands talents avec lesquels je travaille au quotidien. Et tous ensemble, nous avons pu transformer nos idées en produits, notamment en France, en Europe, aux Etats-Unis et au Japon, et créer une entreprise, Wany Robotics&quot;, s'enthousiasme-t-il. François Pierrot rappelle que la démarche d'innovation est en fait la conjonction d'un problème théorique qui, en général, sert de fil conducteur à une thèse, et d'un problème industriel. De cette rencontre va émerger des prototypes, à la fois cohérents avec la démarche scientifique théorique et proche du besoin industriel. &quot;C'est à partir de ces prototypes que nous allons pouvoir faire des démonstrations auprès d'industriels potentiellement intéressés et chercher à aller le plus loin possible afin d'aboutir à des solutions crédibles qui puissent avoir un sens à la fois scientifique, technique et, éventuellement, économique, si l'objectif est de mettre un produit sur le marché&quot;, résume-t-il. C'est en appliquant cette démarche que son équipe a conçu le robot parallèle le plus rapide de tout le marché mondial. &quot;La clé de l'innovation de ce robot ce sont les quatre chaînes en parallèle qui agissent toutes en même temps sur un seul organe ce qui permet de déplacer extrêmement vite par exemple des chocolats lors de leur mise en boîte ou des poissons dans des barquettes, voire, dans le secteur de la microélectronique, déplacer le plus vite possible des composants que l'on cherche à assembler&quot;, explique-t-il. Aujourd'hui, François Pierrot poursuit différents projets, en particulier avec une fondation de recherche privée espagnole, Tecnalia. &quot;Cette fondation a été pour nous le véritable relais pour transformer nos connaissances en avantages compétitifs dans les entreprises&quot;, souligne le chercheur du Lirmm. Il y a quatre ans, cette fondation a même créé une filiale à Montpellier. La chance, toujours cette chance qu'évoque François Pierrot. Celle de travailler dans un établissement de recherche qui l'a &quot;laissé vivre sa vie&quot;, de collaborer avec des collègues remarquablement créatifs, enfin de trouver le relais nécessaire avec Tecnalia. Et puis beaucoup d'idées, originales. Telle est la recette pour innover selon le chercheur de Montpellier.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67385.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Produire du biogaz et absorber du CO2 grâce à des micro-algues</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inria/Sophia Antipolis-Méditerranée - Olivier Bernard : tél. : +33 [4]92 38 77 85 - email : olivier.bernard@inria.fr</contact>
      <texte>Utiliser la digestion de micro-algues par des bactéries pour produire du biométhane biocarburant apparaît comme une solution prometteuse pour l'avenir. Avec une croissance plus rapide que les autres végétaux et une utilisation plus efficace de la lumière, les micro-algues présentent en effet un bon rendement énergétique. Depuis plusieurs années, l'équipe projet Biocore de l'Inria Sophia Antipolis-Méditerranée travaille sur le sujet en collaboration avec ses partenaires de l'Inra et de l'Ifremer. Et visiblement, les résultats sont au rendez-vous puisque deux brevets ont déjà été déposés, en 2006 puis en 2009. Ils concernent un procédé de méthanisation des micro-algues qui permet d'utiliser des résidus de la digestion, comme l'ammoniac et les engrais phosphatés, pour nourrir les algues elles-mêmes. Le couplage &quot;production culture&quot; permet ainsi de limiter les rejets dans l'environnement. De plus, le gaz carbonique fixé par les micro-algues au cours de la photosynthèse est valorisé. Aujourd'hui, l'Inria est ses partenaires entament une seconde phase d'optimisation de ce procédé dans le cadre du projet ANR (Agence Nationale de la Recherche) Symbiose auquel participent également Ecosym, qui est un laboratoire du CNRS, et l'entreprise Naskéo Environnement, spécialisée dans la valorisation des déchets. Cela passe notamment par la modélisation de la croissance et du comportement des populations d'algues et de bactéries. Ainsi l'équipe Biocore de l'Inria a conçu des modèles du comportement des micro-algues et des bactéries, modèles qui, dans un second temps, ont été implantés dans des simulateurs numériques. Grâce à ces derniers, il est alors possible de réaliser des expérimentations in silico à moindre coût, par exemple estimer les meilleures conditions d'exposition au soleil ou d'alimentation des algues pour la production d'une quantité élevée de biogaz. La mise en place d'un premier système pilote, en extérieur, composé d'un bassin de culture ovoïde et d'un méthaniseur va permettre ainsi de valider en conditions réelles les résultats obtenus en laboratoire. Restera ensuite à franchir une nouvelle étape, celle du pilote industriel. Pour l'heure, une autre piste est également explorer dans le cadre du projet Symbiose. Il s'agit d'utiliser les micro-algues pour &quot;nettoyer&quot; les fumées d'usines. Les micro-algues peuvent en effet ingérer une proportion de CO2 pour leur croissance. Aussi pourrait-on les utiliser dans une première étape comme une sorte de filtre, avant de les réutiliser dans une seconde pour produire du biogaz ou du biocarburant.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67386.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Des réseaux de capteurs sans fil à moindre coût pour les usines</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inria/Paris-Rocquencourt - Pascale Minet : tél. : +33 (0)1 39 63 52 33 - email : pascale.minet@inria.fr</contact>
      <texte>Le réseau sans fil est un concept qui évoque évidemment les secteurs de la téléphonie et de l'Internet mobiles. Pour autant, il existe d'autres types de réseaux sans fil, plus complexes, dont le fonctionnement ne nécessite pas l'utilisation de relais fixes, comme pour les télécommunications, mais de relais mobiles. Il s'agit de réseaux qui permettent de communiquer avec des capteurs dispersés sur de vastes sites industriels non équipés de réseau câblé afin d'indiquer le dépassement d'un seuil de pollution ou de degré d'usure d'éléments de machines. Le problème est que ces informations sont envoyées par ondes radio dont la portée n'est que de quelques dizaines de mètres. D'où la nécessité d'utiliser des capteurs relais intermédiaires. &quot;La difficulté est de combiner les exigences des industriels, à savoir minimiser la consommation énergétique, la plupart des capteurs fonctionnant sur batteries, et garantir l'envoi du message dans les délais impartis, tout en étant compatible avec les interfaces existantes&quot;, explique Pascale Minet, de l'équipe-projet Hipercom de l'Inria. Ajoutons que les capteurs ne disposant que de capacités de mémoire très limitées, les programmes développés doivent être très simples. Dans le cadre du projet ANR (Agence Nationale de la Recherche) Ocari, que coordonne EDF et qui rassemble aussi bien des acteurs du secteur académique comme les universités de Clermont-Ferrand, Toulouse et Paris-Sud, et l'Inria, que des industriels (DCNS et Telit), l'Inria a mis au point un protocole qui permet de choisir les bons relais en prenant en compte l'existence de relais mobile, par exemple des capteurs portés par un intervenant humain. Des capteurs qui disposent de trois états possibles : transmission, réception, veille. &quot;Notre protocole vise à les laisser le plus souvent en veille, tout en garantissant l'envoi du message dans les délais, en évitant de passer toujours par les mêmes capteurs&quot;, précise la chercheuse de l'Inria. Dès septembre prochain, des tests en vraie grandeur doivent réalisés dans les usines d'EDF et du constructeur naval militaire qu'est la DCNS.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67387.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Caractéristiques des plantes : mise en service de la plus grande base de données du monde</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Laboratoire d'Ecologie Alpine : - Sandra Lavorel : tél. : +33 (0)4 76 63 56 61 - email : sandra.lavorel@ujf-grenoble.fr Centre d'Ecologie Fonctionnelle et Evolutive - Eric Garnier : tél. : +33 (0)4 67 61 32 42 - email : eric.garnier@cef.cnrs.fr</contact>
      <texte>Ce sont les caractéristiques structurales, physiologiques et reproductives des plantes qui déterminent la manière dont celles-ci se battent pour avoir accès à leurs ressources, grandissent et affectent leurs écosystèmes. Or connaître ces &quot;traits fonctionnels&quot; comme on les appelle est utile, notamment pour déterminer l'influence des végétaux sur les cycles de l'eau et et du carbone. Mais rassembler des données sur un grand nombre d'espèces de plantes pour alimenter des modèles afin de permettre à ces derniers de mieux représenter les effets des changements environnementaux, comme le réchauffement climatique, sur les écosystèmes, est resté difficile jusqu'ici. D'où l'importance de l'initiative TRY qui, en compilant 93 bases de données, constitue aujourd'hui la plus grande base de données du monde sur les caractéristiques des plantes. Une base de données à l'intérieur de laquelle les traits fonctionnels ont été classés en 52 groupes qui vont de la hauteur et de la longévité de la plante à la taille de la graine, en passant par le contenu en azote de la feuille ou la porosité du bois. 4 années et la collaboration de nombreux scientifiques issus de 106 laboratoires dans le monde, dont le Laboratoire d'Ecologie Alpine (CNRS/Université Joseph Fourier/Université de Savoie) de Grenoble et le Centre d'Ecologie Fonctionnelle et Evolutive (CNRS/Universités de Montpellier 1, 2, 3 et de Nîmes/SupAgro/Cirad/EPHE/IRD/INRA) de Montpellier, auront été nécessaires pour compiler 3 millions de ces données concernant 69.000 des 300.000 espèces de plantes existantes. TRY devrait donc permettre d'améliorer la modélisation du &quot;système Terre&quot; en remettant notamment en cause la manière dont les modèles globaux de végétation classent les plantes en un nombre réduit de grands types, comme par exemple les arbres à feuillage persistant. Ainsi les premières analyses réalisées à l'aide de cette base ont montré que la variabilité des traits fonctionnels des plantes était très importante au sein même de ces types. Les individus d'une même espèce peuvent en effet montrer des différences significatives entre eux en fonction des contraintes environnementales auxquelles ils sont soumis. Aussi s'avère-t-il nécessaire de construire des types plus précis basés sur des données de terrain afin que les modèles utilisés soit plus fiables et rendent mieux compte de la biodiversité réelle.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67388.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Du côté des pôles</rubrique>
      <titre>Premiers résultats significatifs d'un projet important pour l'industrie fromagère</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Actilait - Eric Notz - email : e.notz@actilait.com</contact>
      <texte>Même s'il existe d'autres enzymes protéolytiques, d'origine animale, microbienne, voire végétale, qui présentent cette capacité à coaguler le lait, la présure de veau reste aujourd'hui un agent coagulant important utilisé dans la première étape de la fabrication d'un fromage. 4 grands groupes et une dizaine de PME, dont deux basées en France, se partagent cet énorme marché, chacun de ces acteurs produisant ces enzymes selon un mode de fabrication qui lui est propre. C'est dans ce contexte qu'a été lancé COAG, un projet labellisé par le pôle Vitagora, dont le principal objectif est de déterminer quelle est l'influence des supports de ces préparations enzymatiques coagulantes sur le rendement et la qualité des fromages produits. Les résultats obtenus lors de la première étape de ce projet confirment qu'il existe bien une variabilité significative de la composition non enzymatique des coagulants. &quot;Dans la fabrication d'un fromage, la première étape, dite de coagulation, que l'on appelle le caillage, consiste à mettre dans une cuve une dose de préparation coagulante pouvant varier de dix à plus de cent millilitres pour 100 litres de lait. Il s'agit donc de très faibles doses, des doses parfois même qualifiables d'homéopathiques&quot;, rappelle Eric Notz, délégué régional d'Actilait et coordinateur du projet COAG réalisé dans le cadre de l'Unité Mixte Technologique (UMT) de Poligny [1]. S'il existe différentes enzymes coagulantes, la présure de veau reste aujourd'hui très utilisée. Rappelons que cette préparation coagulante extraite de la caillette, c'est-à-dire la quatrième proche de l'estomac de jeunes ruminants abattus avant sevrage, contient deux enzymes actives : la chymosine, majoritaire, et la pepsine dont la proportion augmente avec l'âge du veau. En plus des enzymes coagulantes, les différentes préparations utilisées en fromagerie renferment également d'autres éléments, ce que les spécialistes appellent le &quot;support&quot; et dont la composition varie d'un fabricant à un autre. &quot;Or on estime que ce support, qui peut contenir du NaCl, du phosphate, une fraction azotée et des conservateurs, pourrait contribuer à l'élaboration des caractéristiques sensorielles des fromages affinés&quot;, précise le coordinateur de COAG. La première phase de ce projet a donc consisté à réaliser une enquête de terrain visant à brosser un panorama général des coagulants disponibles sur le marché. A cette occasion, la composition chimique d'un ensemble d'échantillons représentatifs a été analysée. Les résultats obtenus confirment qu'il existe une variabilité significative de la composition non enzymatique de ces coagulants. &quot;Les différences sont visibles à la fois sur la composition minérale et sur la composition protéique des préparations coagulantes. Elles dépendent non seulement du type d'enzyme mais aussi des fabricants &quot;, indique Eric Notz. Il semblerait en effet qu'en plus du type d'enzyme, ce sont les modes de préparation et d'extraction utilisés qui modulent la composition minérale et protéique des coagulants. Précisons que des résultats identiques ont été obtenus sur des coagulants dits &quot;traditionnels&quot; fabriqués en fromagerie. Importants, ces premiers résultats devraient faire l'objet d'une publication scientifique au cours des prochains mois. Un projet sous l'oeil attentif de la profession Pour l'heure, COAG se poursuit, à l'UMT de Poligny. L'INRA continue à développer des techniques de dosage immunochimique pour détecter et quantifier à très faibles doses la chymosine et la pepsine bovine présentes dans les fromages. Actilait et l'ISBA poursuivent avec l'INRA l'analyse de l'impact des préparations coagulantes industrielles sur les propriétés fromagères du lait. Un projet spécifique est en réflexion concernant l'impact des préparations coagulantes traditionnelles telles que les recuites sur la qualité finale des fromages. Autant de travaux qui se déroulent évidemment sous l'oeil attentif de la profession, tant les enjeux sont importants. &quot;Un fromager recherche avant tout une fonctionnalité qui soit garantie. Or les effets insoupçonnés qui apparaissent parfois, il ne les impute pas à la présure. Cela dit, aussi infime soit la quantité de présure utilisée dans la fabrication d'un fromage, celle-ci renferme peut être des éléments pouvant modifier la qualité du produit final&quot;, estime Eric Notz. A terme, COAG devrait donc permettre la publication d'un certain nombre de recommandations en termes de fabrication destinées aux fournisseurs de présures. (1)L'UMT de Poligny regroupe trois partenaires complémentaires dans le domaine de la filière laitière : l'INRA-URTAL (Unité de Recherche en Technologie et Analyses Laitières) de Poligny, l'Institut des Sciences, des Biotechnologies et de l'Agroalimentaire (ISBA) qui regroupe les 2 ENIL de Franche-Comté (Poligny et Mamirolle), et l'Institut technique du lait et des produits laitiers (Actilait).</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67389.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Des neurones particuliers impliqués dans l'apprentissage rapide de la cartographie des lieux</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inserm - Unité 901 &quot;Institut de Neurobiologie de la Méditerranée&quot; - Jérôme Epsztein : tél. : +33 (0)4 91 82 81 15 - email : epsztein@inmed.univ-mrs.fr</contact>
      <texte>Pour un individu, survivre implique obligatoirement de pouvoir se localiser en permanence dans son environnement. Mais comment le cerveau de cet individu cartographie et mémorise l'environnement dans lequel il évolue afin de lui permettre de s'orienter ? C'est la question à laquelle Jérôme Epsztein, chercheur Inserm au sein de l'Unité 901 &quot;Institut de Neurobiologie de la Méditerranée&quot;, et ses collaborateurs, Michael Brecht de l'Université Humboldt de Berlin et Albert Lee de l'Institut Médical Howard Hugues en Virginie, tentent d'apporter des réponses. Rappelons qu'il y a plus de 40 ans, des cellules dites &quot;de lieu&quot; ont été découvertes chez l'animal. Localisés dans l'hippocampe, ces neurones particuliers ne sont activés que lorsque l'animal se trouve dans un lieu donné de son environnement. D'où leur nom. Reste que jusqu'à présent, personne n'a encore réussi à expliquer pourquoi certains de ces neurones de l'hippocampe sont actifs dans un environnement donné alors que la majorité d'entre eux reste silencieux dans un environnement identique. D'où l'importance des travaux menés par Jérôme Epsztein et ses collaborateurs, des travaux qui les ont conduit à développer une nouvelle technique permettant d'enregistrer in vivo l'activité intracellulaire des &quot;cellules de lieu&quot; chez le rat pendant que celui-ci explore son espace environnant. Très sensible, cette technique permet non seulement d'enregistrer les messages envoyés par les cellules, comme le font déjà les techniques classiques, mais également les messages reçus par les neurones ainsi que des propriétés intrinsèques fondamentales des neurones. Ainsi, grâce à cette technique, les chercheurs ont pu comparer très précisément les propriétés des cellules dites &quot;de lieu&quot; de celles dites &quot;silencieuses&quot;, alors que l'animal explorait un environnement pour la première fois et apprenait donc à s'y repérer. Les enregistrements ainsi effectués ont permis de mettre en évidence, comme les chercheurs le supposaient, que les &quot;cellules de lieu&quot; reçoivent davantage de messages excitateurs que les &quot;celllules silencieuses&quot; dans un environnement donné. Parallèlement, les chercheurs ont observé que les &quot;cellules de lieu&quot; présentent des propriétés intrinsèques différentes des &quot;cellules silencieuses&quot; qui facilitent leur réponse à un stimulus donné. Plus surprenant, ces différences de propriétés intrinsèques ont pu être observées avant même que l'animal ne soit confronté à une nouvelle expérience à mémoriser. Jérôme Epsetein pense que certains cellules de l'hippocampe seraient prédisposées à cartographier et potentiellement à mémoriser le prochain environnement exploré. Reste que le cerveau, complexe et plastique, se réorganise à chaque instant en fonction des sollicitations qu'il reçoit. &quot;Nos travaux s'appliquent à l'étude du cerveau de ces animaux à un instant donné&quot;, souligne Jérôme Epsztein qui estime qu'il se peut fort bien qu'à un autre moment pour appréhender un environnement différent, les &quot;cellules silencieuses&quot; deviennent &quot;cellules de lieu&quot;, suite à une modification de leurs propriétés intrinsèques.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67390.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Des nanotubes de peptides au diamètre parfaitement contrôlé</titre>
      <auteur>ADIT - jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>CEA - Jean-Christophe Cintrat : tél. : +33 (0)1 69 08 21 07 - email : jean-christophe.cintrat@cea.fr</contact>
      <texte>Pouvoir contrôler la taille des nano-objets dans le domaine des nanotechnologies est d'une importance capitale. Cette taille module en effet les propriétés physiques de ces matériaux. Mais jusqu'à présent, les tentatives de contrôle de la taille des architectures par modification de la brique unitaire se sont souvent soldées par des échecs. C'est dans ce contexte que des chercheurs du CEA-iBiTec-S (Institut de Biologie et de Technologies de Saclay), du CNRS et d'Ipsen se sont intéressés à une petite molécule, le Lanréotide, qui est un octapeptide cyclique, c'est-à-dire un peptide composé de 8 acides aminés liés successivement et formant un anneau. Analogue de l'hormone naturelle qu'est la Somatostatine, le Lanréotide, classiquement utilisé comme médicament, possède la propriété de s'assembler dans l'eau en dimères, c'est-à-dire en molécules composées de deux sous-unités. Or ce type de structures auto-assemblées constitue une approche intéressante pour la synthèse de nanomatériaux, la forme et la taille de ces systèmes étant principalement conditionnées par la structure des briques de bases. Supposant que les acides aminés assurant les contacts entre peptides régissent le rayon de courbure des nanotubes, les chercheurs ont alors conçu un modèle géométrique qui explique dans quelle mesure une modification de quelques angströms sur la structure de base du peptide peut influer sur la taille du nanotube. En utilisant ce modèle, ils peuvent ainsi rationaliser, voire prédire, les diamètres des nanotubes générés. Restait alors à procéder à une vérification expérimentale qui a consisté à synthétiser des analogues du Lanréotide en substituant de manière ciblée un acide aminé par un autre. Il s'agissait en effet pour les chercheurs de démontrer que la modification d'un acide aminé impliqué dans un contact entre peptides entraîne une variation du diamètre des nanotubes de manière contrôlée. Ils ont obtenu ainsi une gamme de 17 nanotubes allant de 10 à 36 nm de diamètre en fonction de l'acide aminé incorporé. La caractérisation de ces différentes architectures, réalisée par microscopie électronique et diffusion de rayons X au synchrotron SOLEIL, a permis de démontrer que le diamètre de ces nanotubes est effectivement corrélé à la taille de l'acide aminé introduit et qu'un peptide donné forme spontanément des nanotubes d'un seul diamètre. A terme, ces systèmes auto-assemblés biomimétiques pourraient être utilisés comme moules. Les chercheurs ont montré que l'utilisation de ces moules permet de maîtriser la production de nanotubes de silice de diamètre spécifique, ce qui ouvre la voie à un large panel d'applications dans le domaine des nanotechnologies.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67391.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Identification de gènes clés qui pourraient doper la production d'huile de palme</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Laboratoire de Biogenèse Membranaire - Vincent Arondel - tél. : +33 (0)5 57 57 45 08 - email : vincent.arondel@u-bordeaux2.fr</contact>
      <texte>Le palmier à huile, tout comme le palmier dattier ou encore le cocotier, est un arbre économiquement important puisqu'il représente la première culture oléagineuse au monde, avec 35% de la production mondiale, ainsi que la plus productive à l'hectare, avec 3,5 tonnes à l'hectare par an en moyenne, les variétés les plus récentes pouvant produire jusqu'à 8 à 9 tonnes à l'hectare par an. Cela dit, malgré leur importance économique - on estime que dans 20 ans leur culture devrait représenter 40 à 45% de la production mondiale - et leurs potentialités de développement, ces arbres qui présentent la particularité de ne pouvoir être cultivés que dans les régions chaudes et par conséquent presque exclusivement dans les pays en voie de développement, ne font l'objet que de peu de recherches. D'où l'importance des travaux menés par des chercheurs du Laboratoire de Biogenèse Membranaire (CNRS/Université Bordeaux Ségalen), en collaboration avec un laboratoire américain et des chercheurs camerounais et tunisiens, qui ont permis d'identifier les gènes responsables de l'accumulation de l'huile chez ce palmier. C'est avec la participation active des plateformes de métabolome et d'imagerie (BIC) du Centre de génomique fonctionnelle de Bordeaux et le soutien du Conseil Régional d'Aquitaine, que ces chercheurs ont étudié la régulation transcriptionnelle de l'accumulation de l'huile dans le fruit du palmier à huile. Ils ont comparé les transcriptomes, c'est-à-dire l'ensemble des gènes transcrits, du fruit du palmier à l'huile qui peut contenir jusqu'à 90% d'huile à maturité, à celui du palmier dattier qui n'en contient pas. De la sorte, ils ont pu identifier les gènes clés dans l'accumulation de l'huile. Des résultats qui pourraient permettre d'ouvrir des pistes prometteuses et pouvoir, à terme, augmenter la teneur en huile de ces palmiers mais aussi de certaines graines oléagineuses cultivées en Europe comme le Colza ou le tournesol.</texte>
      <images/>
    </bulletin>
  </bulletins>
</corpus>
