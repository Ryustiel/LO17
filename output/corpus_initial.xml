<?xml version="1.0" encoding="utf-8"?>
<corpus>
  <bulletins>
    <bulletin>
      <fichier>67068.htm</fichier>
      <numero>258</numero>
      <date>21/06/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Physique : Mathias Fink, un bel exemple de chercheur qui innove</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Institut Langevin &quot;Ondes et Images&quot; - Mathias Fink - email : mathias.fink@espci.fr - http://www.institut-langevin.espci.fr</contact>
      <texte>Le 27 avril dernier, le CNRS décernait pour la première fois la Médaille de l'Innovation, dont Valérie Pécresse, ministre de l'Enseignement Supérieur et de la Recherche est à l'origine de la création. Le CNRS souhaite ainsi honorer des chercheurs et ingénieurs travaillant dans des établissements publics de recherche, des universités, des grandes écoles mais aussi des industriels qui développent des innovations marquantes. Pour cette première édition, cette nouvelle distinction a été attribuée à trois chercheurs réputés : l'économiste Esther Duflo, le roboticien François Pierrot et le physicien Mathias Fink. Directeur de l'Institut Langevin &quot;Ondes et Images&quot;, créé en janvier 2009 au sein de l'Ecole de Physique et de Chimie Industrielles de la Ville de Paris (ESPCI), Mathias Fink est un remarquable exemple de ces chercheurs qui innovent. Les travaux de son équipe ont en effet abouti à la création de quatre start-ups, qui totalisent 230 personnes, dans des domaines aussi variés que la médecine, les télécommunications, le multimédia ou encore les objets tactiles. &quot;J'aime transformer des idées de physique très fondamentale en produits innovants&quot;, précise d'emblée Mathias Fink. Mais pour y parvenir, il fallait trouver le &quot;terrain&quot; propice. Et c'est à la fin des années 1980, à l'occasion d'une rencontre avec Georges Charpak, le prix Nobel de Physique 1992, qu'il va le découvrir, au coeur de la Montagne Sainte Geneviève, en plein Paris. Alors physicien au sein d'un des plus grands laboratoires français de physique du solide, Mathias Fink souhaite faire de l'innovation autour du concept de renversement du temps. De la &quot;belle physique&quot; comme la qualifient les connaisseurs, qui plus est qui intéresse quatre grands industriels du secteur aéronautique (Dassault, Aerospatial, Snecma, Turboméca), prêts à financer des travaux. Mais à cette époque, le milieu de la recherche est encore peu enclin à travailler avec l'industrie, d'autant plus si celle-ci est &quot;militaro-industrielle&quot;. Aussi Mathias Fink se retrouve isolé. Georges Charpak lui propose alors de rencontrer Pierre-Gilles de Gennes, alors directeur de l'ESPCI, et Jacques Lewiner, le directeur scientifique. &quot;C'est un endroit sympathique&quot;, lui précise Georges Charpak. &quot;Je les ai rencontré. L'endroit était en effet très sympathique. Ils m'ont alors dit : vous voulez Innovez ? Alors venez&quot;, résume Mathias Fink qui ajoute : &quot;cela a été la chance de ma carrière&quot;. Vous êtes chercheur : amusez-vous C'est ainsi que dès 1990, ce physicien crée le Laboratoire Ondes et Acoustique, dans une école qu'il qualifie d'&quot;unique&quot;. &quot;Innover est particulièrement bien vu à l'ESPCI, et l'on vous donne le feu vert du moment que l'idée proposée est très originale&quot;, précise-t-il. Autre particularité de cette école vraiment pas comme les autres Grandes Ecoles, la pluridisciplinarité qui y règne. Ne cherchez pas, vous n'y trouverez pas comme ailleurs un département de physique, un département de chimie et un département de biologie. &quot;Ici, on vous dit dès le départ : vous êtes chercheur, amusez-vous&quot;, souligne-t-il avec une pointe d'humour. Et c'est en s'amusant que lui et son équipe ont développé les fameux miroirs à retournement temporel qui permettent d'échantillonner et d'enregistrer un champ acoustique incident puis de le réémettre dans une chronologie inversée. Mathias Fink et ses collaborateurs se sont rendus compte en effet que faire revivre à une onde sa vie passée permettait de focaliser cette onde à sa source d'une façon très efficace. Ils commencèrent alors à travailler d'abord sur les ultrasons, puis sur les ondes sismiques et les micro-ondes. Cette équipe aurait pu se limiter à publier d'excellents papiers dans des publications réputées comme Physical Review. Mais ces chercheurs ont compris très vite qu'au-delà de cette &quot;belle physique&quot;, il y avait des applications potentielles. Ainsi le renversement du temps permettait de brûler une tumeur, mais aussi de détruire un composant électronique, ou encore de voir derrière un mur ou d'envoyer des informations à un endroit précis dans une pièce. &quot;Progressivement, nous avons donc développé un certain nombre d'instruments originaux qui ont fini par déboucher sur la création de plusieurs start-ups&quot;, indique-t-il. A partir du concept de renversement du temps, Mathias Fink et son équipe ont découvert qu'il était possible de créer des images d'une autre façon. Aussi sont-ils parvenus à fabriquer des imageurs du corps humain grâce auxquels il est possible d'obtenir 10.000 images par seconde du corps humain. &quot;Nous avons pu alors découvrir que le corps humain était parcouru d'ondes que jamais personne n'avait observé jusqu'alors&quot;, s'enthousiasme-t-il. La pluridisciplinarité, clé de la réussite de l'Institut Langevin &quot;Ondes et Images&quot; Le renversement du temps aurait-il des effets sur l'âge de ceux qui le pratiquent ? Au-delà de la boutade, Mathias Fink, âgé aujourd'hui de 65 ans, pourrait le laisser croire, tant son enthousiasme reste intact. Ainsi, en 2009 a-t-il concrétisé le rapprochement de son laboratoire avec un autre laboratoire de l'ESPCI, celui d'Optique Physique, en créant l'Institut Langevin &quot;Ondes et Images&quot;, dont il est le directeur, Arnaud Tourin et Rémi Carminatti en étant les deux directeurs adjoints. Cette Unité Mixte de Recherche (CNRS/ESPCI ParisTech/UPMC/Université Paris-Diderot), qui compte une centaine de personnes, a pour coeur de métier la physique des ondes. Les recherches qui y sont menées s'étendent des concepts fondamentaux aux applications les plus poussées de l'imagerie multi-ondes (acousto-optique, photo-acoustique, élastographie par ultrasons ou IRM) aux techniques originales de focalisation (retournement temporel, filtre inverse, contrôle de front d'ondes), en passant par la création d'entreprises mettant en oeuvre ces nouvelles technologies dans les domaines du biomédical, des télécommunications, de la domotique, etc. &quot;L'aventure se poursuit, toujours dans la pluridisciplinarité, qui est la clé de notre réussite. Aussi faut-il impérativement la préserver&quot;, conclut-il.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67071.htm</fichier>
      <numero>258</numero>
      <date>21/06/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Recherche pour l'environnement : AllEnvi publie son premier rapport</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>AllEnvi - http://www.allenvi.fr</contact>
      <texte>AllENVI, l'Alliance nationale de recherche pour l'Environnement, a été créée le 9 février 2010, à l'initiative de Valérie Pécresse, ministre de l'Enseignement supérieur et de la Recherche. &quot;L'environnement est un système complexe qui recouvre un champ très étendu, de l'agroécologie à l'aménagement des territoires, en passant par les sciences de la mer ou du climat. Biologie, écologie, physico-chimie, mathématiques appliquées, géographie, sciences économiques et sociales ... Toutes les disciplines sont mobilisées par les sciences environnementales&quot;, rappelle en introduction Roger Genet, Président d'AllEnvi et directeur général du Cemagref. D'où la nécessité pour mieux programmer et coordonner l'interdisciplinarité qui caractérise cette recherche de regrouper les principaux opérateurs de recherche dans le domaine de l'environnement au sein de cette Alliance nationale de recherche pour l'Environnement qui compte 12 membres fondateurs [1] Alimentation, Eau, Climat et Territoires constituent les quatre grands enjeux d'AllEnvi. De véritables défis à relever pour les décennies à venir puisqu'il s'agira notamment en matière d'alimentation de parvenir à nourrir 9 milliards d'individus à l'horizon 2050. Concernant l'eau, son accès devra être garanti au plan mondial, non seulement en qualité mais nécessairement en quantité. Autre défi de taille auquel l'humanité devra faire face, les changements climatiques et l'érosion de la biodiversité. Enfin, toutes les populations de la planète devront respecter un impératif, celui de la qualité environnementale des territoires. Au sein d'AllEnvi, le travail des chercheurs est organisé en 12 groupes thématiques, réunissant plus de 250 experts scientifiques : &quot;Agroécologie et Sol&quot;, &quot;Aliments et Alimentation&quot;, &quot;Biodiversité&quot;, &quot;Biologie des plantes&quot;, &quot;Climat (Evolution, Adaptation, Atténuation, Impacts)&quot;, &quot;Eau&quot;, &quot;Ecotechnologies et Chimie durable&quot;, &quot;Sciences de la mer et Ressources marines&quot;, &quot;Risques environnementaux, naturels et écotoxiques&quot;, &quot;Territoires et Ressources naturelles&quot;, &quot;Villes et Mobilités&quot;, &quot;Evaluation environnementale et Cycle de vie&quot;. &quot;Un nouvel élan a été initié&quot;, déclare le Président d'AllEnvi. &quot;Il revient maintenant à nos 15.000 scientifiques, chercheurs, ingénieurs et techniciens, d'identifier, concevoir, valider et déployer les solutions qui permettront de relever les défis de la transition écologique vers une croissante verte&quot;, conclut-il dans l'introduction du premier rapport publié par cette Alliance nationale de recherche pour l'Environnement. -- [1] BRGM, CEA, Cemagref, Cirad, CNRS, Ifremer, IFSTTAR, INRA, IRD, Conférence des Présidents d'Universités, Météo France, Muséum National d'Histoire Naturelle</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67383.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Une médaille de l'innovation qui récompense un roboticien qui ne cesse d'innover</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Lirmm - François Pierrot - email : francois.pierrot@lirmm.fr</contact>
      <texte>Le 27 avril dernier, le CNRS a décerné pour la première fois la Médaille de l'Innovation. Parmi les trois lauréats, François Pierrot, directeur de recherche au CNRS au sein du Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellier, le LIRMM. Réputé mondialement, ce roboticien a notamment participé à la conception et au développement du robot parallèle le plus rapide du monde dont le brevet a été racheté par l'entreprise américaine leader dans le domaine des systèmes robotisés, Adept. Autant dire que contrairement à beaucoup de gens qui dissertent sur l'innovation, ce chercheur, lui, sait ce qu'est l'innovation puisqu'il la vit et la pratique au quotidien. Qui plus est, il en parle remarquablement bien. &quot;Pour innover, il faut évidemment des idées, c'est indispensable, mais aussi souvent beaucoup de chance. Or depuis le début de ma carrière, je n'ai cessé d'en avoir&quot;, déclare-t-il d'emblée. Il rappelle que la première chance de sa carrière professionnelle est d'avoir été recruté au CNRS &quot;qui me soutient depuis plus de vingt ans et m'accorde une très grande liberté dans mon travail, ce qui est important&quot;. Pour lui, l'innovation n'est pas un travail solitaire, bien au contraire. D'où la nécessité de disposer d'une équipe. Et sa seconde chance est d'avoir été recruté à Montpellier, une ville magnifique qui dispose d'un potentiel de recherche tout à fait exceptionnel et en particulier d'un laboratoire réputé mondialement, le LIRMM. &quot;Ce laboratoire exceptionnel renferme une équipe de robotique qui concentre de grands talents avec lesquels je travaille au quotidien. Et tous ensemble, nous avons pu transformer nos idées en produits, notamment en France, en Europe, aux Etats-Unis et au Japon, et créer une entreprise, Wany Robotics&quot;, s'enthousiasme-t-il. François Pierrot rappelle que la démarche d'innovation est en fait la conjonction d'un problème théorique qui, en général, sert de fil conducteur à une thèse, et d'un problème industriel. De cette rencontre va émerger des prototypes, à la fois cohérents avec la démarche scientifique théorique et proche du besoin industriel. &quot;C'est à partir de ces prototypes que nous allons pouvoir faire des démonstrations auprès d'industriels potentiellement intéressés et chercher à aller le plus loin possible afin d'aboutir à des solutions crédibles qui puissent avoir un sens à la fois scientifique, technique et, éventuellement, économique, si l'objectif est de mettre un produit sur le marché&quot;, résume-t-il. C'est en appliquant cette démarche que son équipe a conçu le robot parallèle le plus rapide de tout le marché mondial. &quot;La clé de l'innovation de ce robot ce sont les quatre chaînes en parallèle qui agissent toutes en même temps sur un seul organe ce qui permet de déplacer extrêmement vite par exemple des chocolats lors de leur mise en boîte ou des poissons dans des barquettes, voire, dans le secteur de la microélectronique, déplacer le plus vite possible des composants que l'on cherche à assembler&quot;, explique-t-il. Aujourd'hui, François Pierrot poursuit différents projets, en particulier avec une fondation de recherche privée espagnole, Tecnalia. &quot;Cette fondation a été pour nous le véritable relais pour transformer nos connaissances en avantages compétitifs dans les entreprises&quot;, souligne le chercheur du Lirmm. Il y a quatre ans, cette fondation a même créé une filiale à Montpellier. La chance, toujours cette chance qu'évoque François Pierrot. Celle de travailler dans un établissement de recherche qui l'a &quot;laissé vivre sa vie&quot;, de collaborer avec des collègues remarquablement créatifs, enfin de trouver le relais nécessaire avec Tecnalia. Et puis beaucoup d'idées, originales. Telle est la recette pour innover selon le chercheur de Montpellier.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67385.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Produire du biogaz et absorber du CO2 grâce à des micro-algues</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inria/Sophia Antipolis-Méditerranée - Olivier Bernard : tél. : +33 [4]92 38 77 85 - email : olivier.bernard@inria.fr</contact>
      <texte>Utiliser la digestion de micro-algues par des bactéries pour produire du biométhane biocarburant apparaît comme une solution prometteuse pour l'avenir. Avec une croissance plus rapide que les autres végétaux et une utilisation plus efficace de la lumière, les micro-algues présentent en effet un bon rendement énergétique. Depuis plusieurs années, l'équipe projet Biocore de l'Inria Sophia Antipolis-Méditerranée travaille sur le sujet en collaboration avec ses partenaires de l'Inra et de l'Ifremer. Et visiblement, les résultats sont au rendez-vous puisque deux brevets ont déjà été déposés, en 2006 puis en 2009. Ils concernent un procédé de méthanisation des micro-algues qui permet d'utiliser des résidus de la digestion, comme l'ammoniac et les engrais phosphatés, pour nourrir les algues elles-mêmes. Le couplage &quot;production culture&quot; permet ainsi de limiter les rejets dans l'environnement. De plus, le gaz carbonique fixé par les micro-algues au cours de la photosynthèse est valorisé. Aujourd'hui, l'Inria est ses partenaires entament une seconde phase d'optimisation de ce procédé dans le cadre du projet ANR (Agence Nationale de la Recherche) Symbiose auquel participent également Ecosym, qui est un laboratoire du CNRS, et l'entreprise Naskéo Environnement, spécialisée dans la valorisation des déchets. Cela passe notamment par la modélisation de la croissance et du comportement des populations d'algues et de bactéries. Ainsi l'équipe Biocore de l'Inria a conçu des modèles du comportement des micro-algues et des bactéries, modèles qui, dans un second temps, ont été implantés dans des simulateurs numériques. Grâce à ces derniers, il est alors possible de réaliser des expérimentations in silico à moindre coût, par exemple estimer les meilleures conditions d'exposition au soleil ou d'alimentation des algues pour la production d'une quantité élevée de biogaz. La mise en place d'un premier système pilote, en extérieur, composé d'un bassin de culture ovoïde et d'un méthaniseur va permettre ainsi de valider en conditions réelles les résultats obtenus en laboratoire. Restera ensuite à franchir une nouvelle étape, celle du pilote industriel. Pour l'heure, une autre piste est également explorer dans le cadre du projet Symbiose. Il s'agit d'utiliser les micro-algues pour &quot;nettoyer&quot; les fumées d'usines. Les micro-algues peuvent en effet ingérer une proportion de CO2 pour leur croissance. Aussi pourrait-on les utiliser dans une première étape comme une sorte de filtre, avant de les réutiliser dans une seconde pour produire du biogaz ou du biocarburant.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67386.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Des réseaux de capteurs sans fil à moindre coût pour les usines</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inria/Paris-Rocquencourt - Pascale Minet : tél. : +33 (0)1 39 63 52 33 - email : pascale.minet@inria.fr</contact>
      <texte>Le réseau sans fil est un concept qui évoque évidemment les secteurs de la téléphonie et de l'Internet mobiles. Pour autant, il existe d'autres types de réseaux sans fil, plus complexes, dont le fonctionnement ne nécessite pas l'utilisation de relais fixes, comme pour les télécommunications, mais de relais mobiles. Il s'agit de réseaux qui permettent de communiquer avec des capteurs dispersés sur de vastes sites industriels non équipés de réseau câblé afin d'indiquer le dépassement d'un seuil de pollution ou de degré d'usure d'éléments de machines. Le problème est que ces informations sont envoyées par ondes radio dont la portée n'est que de quelques dizaines de mètres. D'où la nécessité d'utiliser des capteurs relais intermédiaires. &quot;La difficulté est de combiner les exigences des industriels, à savoir minimiser la consommation énergétique, la plupart des capteurs fonctionnant sur batteries, et garantir l'envoi du message dans les délais impartis, tout en étant compatible avec les interfaces existantes&quot;, explique Pascale Minet, de l'équipe-projet Hipercom de l'Inria. Ajoutons que les capteurs ne disposant que de capacités de mémoire très limitées, les programmes développés doivent être très simples. Dans le cadre du projet ANR (Agence Nationale de la Recherche) Ocari, que coordonne EDF et qui rassemble aussi bien des acteurs du secteur académique comme les universités de Clermont-Ferrand, Toulouse et Paris-Sud, et l'Inria, que des industriels (DCNS et Telit), l'Inria a mis au point un protocole qui permet de choisir les bons relais en prenant en compte l'existence de relais mobile, par exemple des capteurs portés par un intervenant humain. Des capteurs qui disposent de trois états possibles : transmission, réception, veille. &quot;Notre protocole vise à les laisser le plus souvent en veille, tout en garantissant l'envoi du message dans les délais, en évitant de passer toujours par les mêmes capteurs&quot;, précise la chercheuse de l'Inria. Dès septembre prochain, des tests en vraie grandeur doivent réalisés dans les usines d'EDF et du constructeur naval militaire qu'est la DCNS.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67387.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Caractéristiques des plantes : mise en service de la plus grande base de données du monde</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Laboratoire d'Ecologie Alpine : - Sandra Lavorel : tél. : +33 (0)4 76 63 56 61 - email : sandra.lavorel@ujf-grenoble.fr Centre d'Ecologie Fonctionnelle et Evolutive - Eric Garnier : tél. : +33 (0)4 67 61 32 42 - email : eric.garnier@cef.cnrs.fr</contact>
      <texte>Ce sont les caractéristiques structurales, physiologiques et reproductives des plantes qui déterminent la manière dont celles-ci se battent pour avoir accès à leurs ressources, grandissent et affectent leurs écosystèmes. Or connaître ces &quot;traits fonctionnels&quot; comme on les appelle est utile, notamment pour déterminer l'influence des végétaux sur les cycles de l'eau et et du carbone. Mais rassembler des données sur un grand nombre d'espèces de plantes pour alimenter des modèles afin de permettre à ces derniers de mieux représenter les effets des changements environnementaux, comme le réchauffement climatique, sur les écosystèmes, est resté difficile jusqu'ici. D'où l'importance de l'initiative TRY qui, en compilant 93 bases de données, constitue aujourd'hui la plus grande base de données du monde sur les caractéristiques des plantes. Une base de données à l'intérieur de laquelle les traits fonctionnels ont été classés en 52 groupes qui vont de la hauteur et de la longévité de la plante à la taille de la graine, en passant par le contenu en azote de la feuille ou la porosité du bois. 4 années et la collaboration de nombreux scientifiques issus de 106 laboratoires dans le monde, dont le Laboratoire d'Ecologie Alpine (CNRS/Université Joseph Fourier/Université de Savoie) de Grenoble et le Centre d'Ecologie Fonctionnelle et Evolutive (CNRS/Universités de Montpellier 1, 2, 3 et de Nîmes/SupAgro/Cirad/EPHE/IRD/INRA) de Montpellier, auront été nécessaires pour compiler 3 millions de ces données concernant 69.000 des 300.000 espèces de plantes existantes. TRY devrait donc permettre d'améliorer la modélisation du &quot;système Terre&quot; en remettant notamment en cause la manière dont les modèles globaux de végétation classent les plantes en un nombre réduit de grands types, comme par exemple les arbres à feuillage persistant. Ainsi les premières analyses réalisées à l'aide de cette base ont montré que la variabilité des traits fonctionnels des plantes était très importante au sein même de ces types. Les individus d'une même espèce peuvent en effet montrer des différences significatives entre eux en fonction des contraintes environnementales auxquelles ils sont soumis. Aussi s'avère-t-il nécessaire de construire des types plus précis basés sur des données de terrain afin que les modèles utilisés soit plus fiables et rendent mieux compte de la biodiversité réelle.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67388.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Du côté des pôles</rubrique>
      <titre>Premiers résultats significatifs d'un projet important pour l'industrie fromagère</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Actilait - Eric Notz - email : e.notz@actilait.com</contact>
      <texte>Même s'il existe d'autres enzymes protéolytiques, d'origine animale, microbienne, voire végétale, qui présentent cette capacité à coaguler le lait, la présure de veau reste aujourd'hui un agent coagulant important utilisé dans la première étape de la fabrication d'un fromage. 4 grands groupes et une dizaine de PME, dont deux basées en France, se partagent cet énorme marché, chacun de ces acteurs produisant ces enzymes selon un mode de fabrication qui lui est propre. C'est dans ce contexte qu'a été lancé COAG, un projet labellisé par le pôle Vitagora, dont le principal objectif est de déterminer quelle est l'influence des supports de ces préparations enzymatiques coagulantes sur le rendement et la qualité des fromages produits. Les résultats obtenus lors de la première étape de ce projet confirment qu'il existe bien une variabilité significative de la composition non enzymatique des coagulants. &quot;Dans la fabrication d'un fromage, la première étape, dite de coagulation, que l'on appelle le caillage, consiste à mettre dans une cuve une dose de préparation coagulante pouvant varier de dix à plus de cent millilitres pour 100 litres de lait. Il s'agit donc de très faibles doses, des doses parfois même qualifiables d'homéopathiques&quot;, rappelle Eric Notz, délégué régional d'Actilait et coordinateur du projet COAG réalisé dans le cadre de l'Unité Mixte Technologique (UMT) de Poligny [1]. S'il existe différentes enzymes coagulantes, la présure de veau reste aujourd'hui très utilisée. Rappelons que cette préparation coagulante extraite de la caillette, c'est-à-dire la quatrième proche de l'estomac de jeunes ruminants abattus avant sevrage, contient deux enzymes actives : la chymosine, majoritaire, et la pepsine dont la proportion augmente avec l'âge du veau. En plus des enzymes coagulantes, les différentes préparations utilisées en fromagerie renferment également d'autres éléments, ce que les spécialistes appellent le &quot;support&quot; et dont la composition varie d'un fabricant à un autre. &quot;Or on estime que ce support, qui peut contenir du NaCl, du phosphate, une fraction azotée et des conservateurs, pourrait contribuer à l'élaboration des caractéristiques sensorielles des fromages affinés&quot;, précise le coordinateur de COAG. La première phase de ce projet a donc consisté à réaliser une enquête de terrain visant à brosser un panorama général des coagulants disponibles sur le marché. A cette occasion, la composition chimique d'un ensemble d'échantillons représentatifs a été analysée. Les résultats obtenus confirment qu'il existe une variabilité significative de la composition non enzymatique de ces coagulants. &quot;Les différences sont visibles à la fois sur la composition minérale et sur la composition protéique des préparations coagulantes. Elles dépendent non seulement du type d'enzyme mais aussi des fabricants &quot;, indique Eric Notz. Il semblerait en effet qu'en plus du type d'enzyme, ce sont les modes de préparation et d'extraction utilisés qui modulent la composition minérale et protéique des coagulants. Précisons que des résultats identiques ont été obtenus sur des coagulants dits &quot;traditionnels&quot; fabriqués en fromagerie. Importants, ces premiers résultats devraient faire l'objet d'une publication scientifique au cours des prochains mois. Un projet sous l'oeil attentif de la profession Pour l'heure, COAG se poursuit, à l'UMT de Poligny. L'INRA continue à développer des techniques de dosage immunochimique pour détecter et quantifier à très faibles doses la chymosine et la pepsine bovine présentes dans les fromages. Actilait et l'ISBA poursuivent avec l'INRA l'analyse de l'impact des préparations coagulantes industrielles sur les propriétés fromagères du lait. Un projet spécifique est en réflexion concernant l'impact des préparations coagulantes traditionnelles telles que les recuites sur la qualité finale des fromages. Autant de travaux qui se déroulent évidemment sous l'oeil attentif de la profession, tant les enjeux sont importants. &quot;Un fromager recherche avant tout une fonctionnalité qui soit garantie. Or les effets insoupçonnés qui apparaissent parfois, il ne les impute pas à la présure. Cela dit, aussi infime soit la quantité de présure utilisée dans la fabrication d'un fromage, celle-ci renferme peut être des éléments pouvant modifier la qualité du produit final&quot;, estime Eric Notz. A terme, COAG devrait donc permettre la publication d'un certain nombre de recommandations en termes de fabrication destinées aux fournisseurs de présures. (1)L'UMT de Poligny regroupe trois partenaires complémentaires dans le domaine de la filière laitière : l'INRA-URTAL (Unité de Recherche en Technologie et Analyses Laitières) de Poligny, l'Institut des Sciences, des Biotechnologies et de l'Agroalimentaire (ISBA) qui regroupe les 2 ENIL de Franche-Comté (Poligny et Mamirolle), et l'Institut technique du lait et des produits laitiers (Actilait).</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67389.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Des neurones particuliers impliqués dans l'apprentissage rapide de la cartographie des lieux</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Inserm - Unité 901 &quot;Institut de Neurobiologie de la Méditerranée&quot; - Jérôme Epsztein : tél. : +33 (0)4 91 82 81 15 - email : epsztein@inmed.univ-mrs.fr</contact>
      <texte>Pour un individu, survivre implique obligatoirement de pouvoir se localiser en permanence dans son environnement. Mais comment le cerveau de cet individu cartographie et mémorise l'environnement dans lequel il évolue afin de lui permettre de s'orienter ? C'est la question à laquelle Jérôme Epsztein, chercheur Inserm au sein de l'Unité 901 &quot;Institut de Neurobiologie de la Méditerranée&quot;, et ses collaborateurs, Michael Brecht de l'Université Humboldt de Berlin et Albert Lee de l'Institut Médical Howard Hugues en Virginie, tentent d'apporter des réponses. Rappelons qu'il y a plus de 40 ans, des cellules dites &quot;de lieu&quot; ont été découvertes chez l'animal. Localisés dans l'hippocampe, ces neurones particuliers ne sont activés que lorsque l'animal se trouve dans un lieu donné de son environnement. D'où leur nom. Reste que jusqu'à présent, personne n'a encore réussi à expliquer pourquoi certains de ces neurones de l'hippocampe sont actifs dans un environnement donné alors que la majorité d'entre eux reste silencieux dans un environnement identique. D'où l'importance des travaux menés par Jérôme Epsztein et ses collaborateurs, des travaux qui les ont conduit à développer une nouvelle technique permettant d'enregistrer in vivo l'activité intracellulaire des &quot;cellules de lieu&quot; chez le rat pendant que celui-ci explore son espace environnant. Très sensible, cette technique permet non seulement d'enregistrer les messages envoyés par les cellules, comme le font déjà les techniques classiques, mais également les messages reçus par les neurones ainsi que des propriétés intrinsèques fondamentales des neurones. Ainsi, grâce à cette technique, les chercheurs ont pu comparer très précisément les propriétés des cellules dites &quot;de lieu&quot; de celles dites &quot;silencieuses&quot;, alors que l'animal explorait un environnement pour la première fois et apprenait donc à s'y repérer. Les enregistrements ainsi effectués ont permis de mettre en évidence, comme les chercheurs le supposaient, que les &quot;cellules de lieu&quot; reçoivent davantage de messages excitateurs que les &quot;celllules silencieuses&quot; dans un environnement donné. Parallèlement, les chercheurs ont observé que les &quot;cellules de lieu&quot; présentent des propriétés intrinsèques différentes des &quot;cellules silencieuses&quot; qui facilitent leur réponse à un stimulus donné. Plus surprenant, ces différences de propriétés intrinsèques ont pu être observées avant même que l'animal ne soit confronté à une nouvelle expérience à mémoriser. Jérôme Epsetein pense que certains cellules de l'hippocampe seraient prédisposées à cartographier et potentiellement à mémoriser le prochain environnement exploré. Reste que le cerveau, complexe et plastique, se réorganise à chaque instant en fonction des sollicitations qu'il reçoit. &quot;Nos travaux s'appliquent à l'étude du cerveau de ces animaux à un instant donné&quot;, souligne Jérôme Epsztein qui estime qu'il se peut fort bien qu'à un autre moment pour appréhender un environnement différent, les &quot;cellules silencieuses&quot; deviennent &quot;cellules de lieu&quot;, suite à une modification de leurs propriétés intrinsèques.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67390.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Des nanotubes de peptides au diamètre parfaitement contrôlé</titre>
      <auteur>ADIT - jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>CEA - Jean-Christophe Cintrat : tél. : +33 (0)1 69 08 21 07 - email : jean-christophe.cintrat@cea.fr</contact>
      <texte>Pouvoir contrôler la taille des nano-objets dans le domaine des nanotechnologies est d'une importance capitale. Cette taille module en effet les propriétés physiques de ces matériaux. Mais jusqu'à présent, les tentatives de contrôle de la taille des architectures par modification de la brique unitaire se sont souvent soldées par des échecs. C'est dans ce contexte que des chercheurs du CEA-iBiTec-S (Institut de Biologie et de Technologies de Saclay), du CNRS et d'Ipsen se sont intéressés à une petite molécule, le Lanréotide, qui est un octapeptide cyclique, c'est-à-dire un peptide composé de 8 acides aminés liés successivement et formant un anneau. Analogue de l'hormone naturelle qu'est la Somatostatine, le Lanréotide, classiquement utilisé comme médicament, possède la propriété de s'assembler dans l'eau en dimères, c'est-à-dire en molécules composées de deux sous-unités. Or ce type de structures auto-assemblées constitue une approche intéressante pour la synthèse de nanomatériaux, la forme et la taille de ces systèmes étant principalement conditionnées par la structure des briques de bases. Supposant que les acides aminés assurant les contacts entre peptides régissent le rayon de courbure des nanotubes, les chercheurs ont alors conçu un modèle géométrique qui explique dans quelle mesure une modification de quelques angströms sur la structure de base du peptide peut influer sur la taille du nanotube. En utilisant ce modèle, ils peuvent ainsi rationaliser, voire prédire, les diamètres des nanotubes générés. Restait alors à procéder à une vérification expérimentale qui a consisté à synthétiser des analogues du Lanréotide en substituant de manière ciblée un acide aminé par un autre. Il s'agissait en effet pour les chercheurs de démontrer que la modification d'un acide aminé impliqué dans un contact entre peptides entraîne une variation du diamètre des nanotubes de manière contrôlée. Ils ont obtenu ainsi une gamme de 17 nanotubes allant de 10 à 36 nm de diamètre en fonction de l'acide aminé incorporé. La caractérisation de ces différentes architectures, réalisée par microscopie électronique et diffusion de rayons X au synchrotron SOLEIL, a permis de démontrer que le diamètre de ces nanotubes est effectivement corrélé à la taille de l'acide aminé introduit et qu'un peptide donné forme spontanément des nanotubes d'un seul diamètre. A terme, ces systèmes auto-assemblés biomimétiques pourraient être utilisés comme moules. Les chercheurs ont montré que l'utilisation de ces moules permet de maîtriser la production de nanotubes de silice de diamètre spécifique, ce qui ouvre la voie à un large panel d'applications dans le domaine des nanotechnologies.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67391.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Identification de gènes clés qui pourraient doper la production d'huile de palme</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Laboratoire de Biogenèse Membranaire - Vincent Arondel - tél. : +33 (0)5 57 57 45 08 - email : vincent.arondel@u-bordeaux2.fr</contact>
      <texte>Le palmier à huile, tout comme le palmier dattier ou encore le cocotier, est un arbre économiquement important puisqu'il représente la première culture oléagineuse au monde, avec 35% de la production mondiale, ainsi que la plus productive à l'hectare, avec 3,5 tonnes à l'hectare par an en moyenne, les variétés les plus récentes pouvant produire jusqu'à 8 à 9 tonnes à l'hectare par an. Cela dit, malgré leur importance économique - on estime que dans 20 ans leur culture devrait représenter 40 à 45% de la production mondiale - et leurs potentialités de développement, ces arbres qui présentent la particularité de ne pouvoir être cultivés que dans les régions chaudes et par conséquent presque exclusivement dans les pays en voie de développement, ne font l'objet que de peu de recherches. D'où l'importance des travaux menés par des chercheurs du Laboratoire de Biogenèse Membranaire (CNRS/Université Bordeaux Ségalen), en collaboration avec un laboratoire américain et des chercheurs camerounais et tunisiens, qui ont permis d'identifier les gènes responsables de l'accumulation de l'huile chez ce palmier. C'est avec la participation active des plateformes de métabolome et d'imagerie (BIC) du Centre de génomique fonctionnelle de Bordeaux et le soutien du Conseil Régional d'Aquitaine, que ces chercheurs ont étudié la régulation transcriptionnelle de l'accumulation de l'huile dans le fruit du palmier à huile. Ils ont comparé les transcriptomes, c'est-à-dire l'ensemble des gènes transcrits, du fruit du palmier à l'huile qui peut contenir jusqu'à 90% d'huile à maturité, à celui du palmier dattier qui n'en contient pas. De la sorte, ils ont pu identifier les gènes clés dans l'accumulation de l'huile. Des résultats qui pourraient permettre d'ouvrir des pistes prometteuses et pouvoir, à terme, augmenter la teneur en huile de ces palmiers mais aussi de certaines graines oléagineuses cultivées en Europe comme le Colza ou le tournesol.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67392.htm</fichier>
      <numero>259</numero>
      <date>22/07/2011</date>
      <rubrique>Evénement</rubrique>
      <titre>12ème Journée Hélio-SPIR autour de la chimiométrie</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>- Hélio-SPIR - http://www.heliospir.net/actualites/article/34 - Inscription : http://redirectix.bulletins-electroniques.com/jTFx7</contact>
      <texte>Le 30 septembre 2011, à Montpellier, l'Assocation française pour la spectroscopie proche infrarouge, Hélio-SPIR, organise sa conférence annuelle intitulée &quot;La chimiométrie au service de la spectroscopie proche infrarouge&quot;. L'objectif de cette conférence est d'expliquer de façon didactique certaines méthodes chimiométriques appliquées à la spectroscopie proche infrarouge grâce aux experts du domaine. Ces interventions seront suivies d'applications pratiques industrielles, issues de divers domaines (agricole, pharmaceutique ...). Les méthodes abordées seront la discrimination, le transfert inter-instruments, les prétraitements spectroscopiques et l'estimation de la validité d'une prédiction.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67553.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Des PME qui chassent en meute : l'objectif du cluster EDEN</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>EDEN - Thierry Regond : tél. : +33 (0)4 72 08 12 12 email : tregond@sunaero.com - http://www.eden-defense-cluster.com</contact>
      <texte>A ce jour, elles sont 47 entreprises, mais l'objectif affiché est qu'elles soient 80 courant 2012. Elles ont en commun de travailler pour le secteur de la défense, nationale ou internationale, d'être innovantes et, qui plus est, exportatrices. Complémentaires, elles sont toutes adhérentes d'EDEN, un cluster de PME indépendantes créé fin 2007 sous l'égide de la Chambre de Commerce et d'Industrie (CCI) de Lyon et de la Direction Générale de l'Armement (DGA). En fédérant ainsi des PME qui, jusqu'alors, travaillaient isolément, EDEN permet à celles-ci de communiquer davantage entre elles, d'être plus visibles au niveau national et international, valorisant par la même leur savoir-faire, souvent unique, et de développer des actions collectives. Intéressées cette démarche, au moins trois régions françaises, au sein desquelles un certain nombre d'entreprises a été identifié, pourraient intégrer rapidement ce groupement lyonnais au sein d'une fédération en cours de création. &quot;Quand nous avons initié ce projet de cluster, nous étions 5 entreprises partie prenante, dont Sunaero&quot;, rappelle Thierry Regond, vice-président de Sunaero et trésorier d'EDEN. L'idée de la DGA était d'aider les PME travaillant pour la défense afin qu'elles puissent à la fois croître, et par conséquent embaucher et exporter davantage, d'autant plus qu'il s'agit d'un secteur hautement technologique, qui plus est généralement dual. &quot;Nous sommes tous confrontés à la même problématique. Nous dépendons principalement des grands donneurs d'ordre qui, pour certains, tentent d'appréhender et de capter nos technologies, sans que nous bénéficions d'un réel retour. D'où la nécessité de protéger nos savoir-faire en faisant prendre conscience à ces donneurs d'ordre, que nous sommes évidemment à leur disposition mais que nous souhaitons en garder la paternité avec une certaine autonomie quant à leur utilisation éventuelle pour d'autres clients, ce qui nous permet une évolution technologique continue et pertinente et nous assure une réelle pérennité&quot;, explique-t-il. Thierry Regond ajoute que si beaucoup de progrès ont été faits ces derniers temps, notamment avec la signature de conventions au niveau national de type Pacte PME qui formalise une réelle volonté des Directions Générales de faire évoluer cette situation, dans les faits cependant, beaucoup reste à faire. La volonté d'EDEN, qui regroupe aujourd'hui 47 entreprises adhérentes, de la TPE qui compte 3 salariés à la PME de 350 à 400 personnes, est donc de préserver les intérêts de chacune de ces entreprises, tout en respectant évidemment des règles très strictes quant à la commercialisation de certains savoir-faire technologiques particulièrement sensibles. Les entreprises adhérentes d'EDEN couvrent principalement 4 domaines d'activités : le transport aérien et terrestre, la protection individuelle, la détection et les mesures, enfin les logiciels embarqués ou pas. Les technologies de pointe qu'elles développent dans ces domaines sont, pour l'essentiel, destinées à des marchés de niches qui n'intéressent donc pas toujours les grands groupes industriels. &quot;Le fait que nous ne soyons pas concurrents mais complémentaires nous permet d'échanger facilement des données techniques commerciales. Aussi, face à un besoin spécifique d'un client, nous sommes désormais capables de nous regrouper afin de proposer une solution technique globale pertinente et généralement inédite&quot;, s'enthousiasme Thierry Regond. Cette manière de &quot;chasser en meute&quot; a d'ores et déjà permis à EDEN d'initier notamment des coopérations techniques dans certains pays comme l'Inde. Pour autant, il n'est pas question que le cluster lyonnais se substitue à ses adhérents. Parallèlement ce dernier organise également pour les entreprises qui en font partie des visites très opérationnelles à l'étranger. &quot;Il s'agit principalement de prendre des contacts avec des entreprises comme nous l'avons fait récemment au Brésil, lors du Salon LAAD (Latin America Aero &amp; Defense)&quot;, précise-t-il. Pas seulement un groupement de PME, mais une sorte d'état d'esprit Au fil des mois, EDEN commence à ressembler à une véritable &quot;meute&quot;. Aussi le cluster lyonnais est-il de plus en plus efficace. &quot;En fédérant nos actions commerciales à l'export, nous sommes de plus en plus visibles. D'où un intérêt croissant des délégations officielles des pays dans lesquels nous participons à des salons et la multiplication de nos contacts avec les donneurs d'ordre étrangers&quot;, constate Thierry Regond qui précise qu'il en est de même en France avec, évidemment, la DGA mais aussi l'armée de terre, l'armée de l'air et les grandes institutions. Dans ce contexte, le développement d'EDEN est observé avec intérêt par d'autres régions françaises, et en particulier la Bretagne, l'Aquitaine et la Bourgogne, trois régions au sein desquelles ont été identifiées des entreprises qui présentent le profil souhaité pour intégrer à terme EDEN. Aussi les responsables du cluster réfléchissent-ils à cette possible intégration, via la création d'une fédération nationale. &quot;Il s'agit de pouvoir regrouper toutes les entreprises qui souhaitent nous rejoindre en leur donnant une certaine autonomie régionale. Nous avons observé en effet que les entités régionales comme les Conseils régionaux, généraux, voire les CCI, souhaitent pouvoir dire leur mot et contribuer à ce véritable élan&quot;. L'Ile-de-France et la région Provence Alpes Côte d'Azur (PACA) sont également très intéressées par EDEN. Persuadés que pour pouvoir prétendre peser sur les décisions il faut être nombreux, les responsables d'EDEN ce sont fixés des objectifs ambitieux, le premier étant d'être 80 adhérents, sans compter les autres régions, au cours du premier trimestre 2012. Particularité d'EDEN : chaque entreprise souhaitant y adhérer doit être agréée par l' ensemble des adhérents. C'est dire si ce cluster n'est pas seulement un regroupement de PME de haute technologie positionnées sur le secteur de la défense, mais a su, malgré son jeune âge, faire naître une sorte d'état d'esprit. Or pour en faire partie, encore faut-il l'avoir et le démontrer.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67554.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Focus</rubrique>
      <titre>Une &quot;boîte à outils&quot; pour l'intégration des technologies 3D au CEA</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>CEA/Leti - Stéphane Lavessière - email : stephane.laveissiere@cea.fr</contact>
      <texte>Beaucoup d'appareils qui &quot;peuplent&quot; notre quotidien renferment des puces électroniques, de nature extrêmement variée. Celles-ci sont fabriquées en série sur des wafers, autrement dit des plaques de silicium, découpées ensuite pour y fabriquer des processeurs, des mémoires stand-alone et des composants programmables. Grâce aux progrès constants réalisés dans la finesse des gravures, l'industrie microélectronique développe des circuits toujours plus puissants et de moins en moins coûteux, comme le prédit la loi de Moore. Reste pourtant que le transistor, motif de base de la microélectronique, est toujours fabriqué sur une même surface plane, autrement dit en deux dimensions. D'où l'idée d'empiler les composants électroniques, en superposant des puces et/ou des wafers les uns sur les autres et en établissant des connexions électriques courtes entre ces composants, directement au travers des différentes couches. Une alternative dite &quot;3D&quot; qui va permettre de réduire encore les coûts et d'augmenter significativement les performances globales des circuits, tout en réduisant leur consommation énergétique. A Grenoble, au sein des équipes du CEA/Leti, les chercheurs travaillent activement à ces développements prometteurs. Une 3D qui mobilise 140 chercheurs et ingénieurs Au CEA/Leti, environ 140 chercheurs et ingénieurs se consacrent aujourd'hui à cette alternative 3D, travaillant à la fois sur les aspects conception de puces, intégration de process et développements spécifiques. Ces derniers portent par exemple sur la façon la plus efficace de manipuler des wafers plus minces qui n'ont plus la même rigidité. Pour relever ce défi, les équipes grenobloises du CEA, comme elles l'ont toujours fait, collaborent étroitement avec les fabricants de matériaux et les fabricants d'équipements de microélectronique. Il s'agit en effet d'être sûr que ces process vont être transférés au milieu industriel et que les partenaires industriels du CEA pourront bénéficier d'une chaîne industrielle complète. Pour les équipes grenobloises, il s'agit également de travailler sur différentes scénarios d'intégration, l'objectif étant de prouver la fonctionnalité des démonstrateurs et les avantages qu'ils présentent notamment en termes de coût et de consommation, autrement dit de montrer que l'approche est économiquement viable. c'est dans ce contexte que le CEA/Leti a mis au point une &quot;boîte à outils&quot; spécifique pour l'intégration 3D. &quot;Notre objectif est de proposer des filières génériques complètes adaptées à différentes catégories de besoins industriels, à partir d'étapes élémentaires de fabrication à combiner ou à adapter&quot;, explique-t-on à la direction du Leti. Pour chacune des technologies développées, les chercheurs grenoblois mesure la maturité des procédés à l'aide d'une échelle comportant cinq niveaux, allant de la démonstration technique du procédé au transfert à l'industriel, en passant par la validation du fonctionnement électrique du procédés sur un dispositif test, la démonstration technique du procédés sous la forme de composant intégré et le prototype industriel. Ce dernier niveau est généralement celui jusqu'au quel vont les composants 3D conçus et réalisés par les équipes du Leti, le transfert à l'industriel ne s'effectuant qu'au cas par cas avec chaque industriel demandeur. Imageur pour téléphone portable, premier exemple de composant utilisant les technologies 3D Au sein du département d'optronique du CEA-Leti, les chercheurs travaillent au développement de technologies en vue d'applications assez diverses, parmi lesquelles les imageurs, c'est-à-dire les caméras, que renferment les téléphones portables. L'objectif est d'améliorer la qualité du traitement d'image tout en réduisant le coût des technologies utilisées. Par exemple, en optimisant la détection des photons, il est alors possible de réduire la taille des pixels tout en diminuant le coût des capteurs. Pour réduire la taille globale du dispositif, les chercheurs du Leti ont d'ores et déjà fait appel aux technologies d'intégration 3D. Ainsi dès 2009, ils ont conçu un module optique utilisant une brique technologique issue de la 3D. Rappelons que jusqu'alors, les imageurs étaient connectés à des circuits périphériques à l'aide de connexions électriques classiques en 2D. Or la technologie dite &quot;TSV&quot; ou Through Silicon Via, développée au Leti, permet la connexion de l'imageur à l'aide de vias traversants le silicium, la connectique étant alors ramenée sous la puce. Obtenue ensuite par &quot;reflow&quot;, cette connexion est comparable au dépôt de composants sur une carte support. D'où la possibilité notamment d'intégrer davantage de circuits sur une même puce, tout en diminuant le coût de fabrication, une fois la procédé d'industrialisation maîtrisé, mais de diminuer également la taille globale du dispositif incluant le bloc optique, et de disposer d'interconnexions plus courtes et, par conséquent, d'accroître la vitesse de transmission des informations plus élevée ce qui permet de maintenir des cadences vidéo confortables. Développé avec succès pour le groupe STMicroelectronics, sur une ligne de 200 mm, ce procédé d'intégration des imageurs est aujourd'hui industrialisé par le même groupe industriel, sur lignes de 300 mm, pour un grand fabricant européen de téléphones portables.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67555.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Focus</rubrique>
      <titre>HABEAT, un projet européen pour mieux comprendre la formation des préférences alimentaires chez l'enfant</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Centre des Sciences du Goût et de l'Alimentation (CSGA) - Sylvie Issanchou - email : sylvie.issanchou@dijon.inra.fr</contact>
      <texte>Les 12 et 13 avril derniers, les 11 partenaires du projet HABEAT, dont le Centre des Sciences du Goût et de l'Alimentation (CSGA), se sont réunis en Grèce pour dresser un bilan des études en cours. Rappelons que ce projet européen, lancé en janvier 2010 et labellisé par le pôle de compétitivité Vitagora, a pour objectif de mieux comprendre les périodes et les mécanismes clés dans la formation des préférences alimentaires chez l'enfant depuis la naissance jusqu'à l'âge de cinq ans. Un premier rapport sur les résultats déjà obtenus sera bientôt remis à la Commission Européenne. Enfin, le 3 novembre prochain, à Varsovie en Pologne, se tiendra une réunion ouverte à tous les utilisateurs potentiels des résultats de HABEAT comme les pédiatres et les industriels. L'occasion de faire un point avec Sylvie Issanchou, Directrice de recherche Inra et coordinatrice de ce projet. &quot;HABEAT est un projet ambitieux dans lequel sont impliquées 10 équipes scientifiques européennes complémentaires. Un tiers d'entre elles est axé sur l'épidémiologie, les deux autres faisant essentiellement de l'expérimentation&quot;, rappelle d'emblée Sylvie Issanchou. Concernant le volet épidémiologique, les chercheurs ont d'ores et déjà dressé un bilan de la littérature existante, constatant ainsi qu'il existe déjà beaucoup de questionnaires autour du comportement alimentaire du jeune enfant et des pratiques ou attitudes parentales qui peuvent l'influencer. Quelques manques ont pu être identifiés concernant en particulier l'attention des parents envers les signaux de faim et de satiété. &quot;Aussi préparons-nous un questionnaire spécifique qui permettrait d'aborder cette question&quot;, précise-t-elle. Autre manque également observé, un outil qui permettrait d'évaluer les préférences alimentaires des enfants, mais via un questionnaire essayant de couvrir différentes caractéristiques sensorielles des aliments. Parallèlement, des données existantes provenant de cohortes d'enfants de 4 pays européens ont pu faire l'objet d'une première série d'analyses. Il s'agit d'observer les effets de différents facteurs tels que la durée de l'allaitement maternel, l'âge d'introduction des aliments autres que le lait dans la diète des enfants (ce que l'on appelle le début de la &quot;diversification&quot;), l'âge d'introduction des fruits et légumes et le niveau d'éducation de la mère sur la consommation des fruits et légumes à l'âge de deux, trois ou quatre ans. &quot;Les effets de ces différents facteurs ne sont pas significatifs pour toutes les cohortes et il semble qu'ils s'estompent avec le temps. Ceci peut être lié au fait que les durées d'allaitement, les âges de diversification et les niveaux de consommation de fruits mais surtout de légumes diffèrent d'un pays à l'autre. Néanmoins, quand la durée d'allaitement a un effet, cet effet est positif : plus les enfants ont été allaité longtemps, plus ils consomment de fruits et de légumes. Quand le niveau d'éducation de la mère a un effet, on observe que plus les mères sont éduquées plus les enfants consomment de fruits et de légumes&quot;, constate Sylvie Issanchou. De nouvelles analyses sont en cours pour comprendre l'origine des différences observées entre pays. Deux légumes, artichaut et salsifis, au menu des enfants Du côté du volet expérimental, deux études ont été lancées, en particulier à Dijon, études conduites en parallèle en Angleterre et au Danemark. &quot;Nous avons en charge les enfants les plus jeunes, c'est-à-dire au moment de la diversification, alors que les Anglais et les Danois s'occupent des enfants entre un et trois ans &quot;, explique la coordinatrice de HABEAT. Pour chacune de ces deux études, il a fallu choisir un légume cible, qui soit à la fois peu consommé par les enfants des trois pays, pas forcément trop apprécié mais non plus totalement rejeté. C'est donc l'artichaut et le salsifis qui ont été choisis. Ainsi 3 groupes d'enfants ont consommé à domicile de l'artichaut, chacun sous la forme d'une recette différente : simple pour le premier groupe, associé à un peu de sucre pour le second, et avec un peu d'huile pour le dernier. &quot;Les enfants étant en phase d'apprentissage, on espère que la composante positive, en l'occurrence le sucre ou l'huile, va être transférée à l'arôme et au goût du légume&quot;, précise-t-elle Une autre étude a été mise en place à Dijon auprès d'environ 70 enfants de 6 crèches, âgés de 2 à 3 ans, qui ont consommés des salsifis, là encore sous la forme de 3 recettes différentes : simple, associés à du sel, enfin accompagnés de muscade. Les chercheurs estiment en effet que la muscade peut compenser la diminution de sel et être ainsi appréciée. &quot;C'est un gros travail qui a pu être réalisé grâce à la coopération que nous avons avec le Service de la petite enfance de la ville de Dijon. Chaque jour il faut se rendre dans les crèches, distribuer les aliments, peser ce qui est servi mais aussi les restes, puisque l'acceptabilité est évaluée à travers la quantité consommée, les enfants étant encore trop petits pour donner leur avis&quot;, rappelle Sylvie Issanchou. Et à chacune de ces &quot;manips&quot;, ce sont des montagnes de données qui sont collectées et qu'il va falloir analyser. Ajouter à cela qu'une autre étude, menée auprès des enfants de 4 écoles de Dijon, est également en cours, l'objectif étant d'observer comment les enfants régulent leur prise alimentaire, soit quand on leur donne quelque chose à manger avant le repas, ou soit quand des produits attractifs sont à portée de leurs mains après le repas. Vous comprenez alors tout l'intérêt de financer un tel projet aux résultats attendus très prometteurs.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67556.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>Découverte d'une signature moléculaire de la déficience intellectuelle</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>- Inserm - Unité 781 &quot;Génétique et épigénétique des maladies métaboliques, neurosensorielles et du développement - Laurence Colleaux : tél. : +33 (0)1 44 49 51 52 - Unité mixte &quot;Institut de génétique et de biologie moléculaire et cellulaire&quot; - Jean-Marc Egly : tél. : +33 (O)6 73 98 19 38</contact>
      <texte>La déficience intellectuelle ou DI est définie comme &quot;un fonctionnement intellectuel général inférieur à la moyenne, qui s'accompagne de limitations significatives du fonctionnement adaptatif&quot;. Près de 3% de la population générale sont concernés par celle-ci. Si 20% des ces DI peuvent être attribuées à des facteurs environnementaux et 40% à des causes génétiques connues, dans près de la moitié des cas les causes de la maladie restent inconnues. D'où l'importance des travaux de Laurence Colleaux, de l'Unité de recherche &quot;Génétique et épigénétique des maladies métaboliques, neurosensorielles et du développement&quot; (Inserm-Université Paris Descartes-Hôpital Necker-Enfants Malades-Fondation Imagine), et de Jean-Marc Egly de l'Unité mixte &quot;Institut de génétique et de biologie moléculaire et cellulaire (Inserm-CNRS-Université de Strasbourg), dont les résultats viennent d'être publiés dans la revue Science datée du 26 août 2011. Parmi les DI, les formes dites &quot;non syndromiques&quot; sont caractérisées par une diminution isolée et non progressive des performances intellectuelles. Les chercheurs se sont donc intéressés à ces formes de déficits, les gènes qui en sont responsables participant directement aux processus liés aux fonctions cognitives (mémorisation, apprentissage, comportement, etc.). Ils ont identifié ainsi une mutation du gène MED23 qui est liée à une DI isolée. MED23 code en effet une des sous-unités d'un large complexe multiprotéique : le Médiateur (MED). Or ce complexe est connu pour son rôle dans une étape clé de la régulation de l'expression des gènes : la transcription. Il permet aux facteurs de transcription spécifiques d'un gène de s'assembler pour interagir avec l'ARN polymérase, enzyme clé de cette étape. Les deux équipes de recherche ont démontré que les cellules de patients atteints de DI présentent un défaut d'expression de certains gènes parmi lesquels les gènes &quot;précoces&quot; JUN et FOS, ces derniers étant impliqués dans l'expression d'une cascade de gènes liés à diverses fonctions cellulaire, notamment au niveau du système nerveux central. Précisons que leur activation rapide et transitoire représente une étape majeure dans le développement et la plasticité cérébrale. La mutation identifiée par les chercheurs conduit à la synthèse d'une protéine MED23 modifiée, devenue incapable d'interagir correctement avec les facteurs spécifiques des deux gènes considérés. Ainsi, dans le cas du gène JUN, l'assemblage permettant la transcription est défectueux suite à un mauvais contact entre la protéine MED23 mutée et le facteur TCF4. Selon Laurence Colleaux, l'étude de patients DI porteurs de mutations modifiant d'autres protéines impliquées dans la transcription, suggère que cette anomalie d'expression des gènes &quot;précoces&quot; puisse être une &quot;signature moléculaire&quot; de ce trouble. Les résultats publiés dans Science apportent donc un nouvel argument en faveur du rôle majeur des anomalies de l'expression génétique dans la recherche des causes de déficiences intellectuelles.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67557.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Actualité Innovation</rubrique>
      <titre>FRISBEE : vers le développement de réfrigérateurs plus &quot;écologiques&quot;</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>- Cemagref/Antony - Graciela Alvarez : tél. : +33 (0)1 40 96 60 17 email : graciela.alvarez@cemagref.fr - FRISBEE : http://www.frisbee-project.eu</contact>
      <texte>Le traditionnel réfrigérateur reste aujourd'hui le meilleur équipement pour refroidir les aliments afin de les conserver. Pour autant, le froid alimentaire représente encore aujourd'hui 8% de la consommation mondiale d'électricité et 2,5% du CO2 produit et rejeté dans l'atmosphère. Dans un contexte où l'Europe préconise de réduire de 20% la consommation énergétique globale, l'Union Européenne a donc lancé en 2010 le projet FRISBEE (Food Refrigeration Innovations for Savety, consumer's Benefit, Environmental impact and Energy optimization along the cold Chain in Europe), qu'elle finance à hauteur de 6 millions d'euros pour une durée de 4 ans. Associant des chercheurs et des indusriels, ce projet qui bénéficie d'un budget global de 8 millions d'euros a pour objectif, non seulement de concevoir le réfrigérateur de demain et des systèmes de contrôle du froid &quot;intelligents&quot; capables de rationaliser la consommation d'énergie, mais aussi les matériaux nouveaux d'emballage ou de revêtement qui optimisent la protection des aliments vis-à-vis des écarts de température, voire de développer de nouvelles technologies de froid comme le froid magnétique. Précisons que ce projet scientifique fait également appel aux spécialistes des sciences économiques et sociales afin de mieux comprendre le comportement des consommateurs européens. Actuellement, les équipes impliquées dans FRISBEE, dont celles du Cemagref, achèvent une première base de données complète à l'échelle européenne sur la chaîne du froid. Celle-ci rassemble les données sur les technologies disponibles, la consommation énergétique, les besoins et les attentes des consommateurs et des industriels de l'agroalimenaire.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67558.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>En direct des laboratoires</rubrique>
      <titre>Une mousse prometteuse pour les fabricants de cosmétiques et de détergents</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>http://onlinelibrary.wiley.com/doi/10.1002/ange.201102115/abstract</contact>
      <texte>En raison de leur texture particulière et des molécules &quot;tensioactives&quot; qui les constituent, les mousses ont souvent des vertus détergentes. Rappelons que les molécules dites &quot;tensioactives&quot; présentent la particularité de se placer spontanément entre l'eau et l'air, ce qui permet de stabiliser des films d'eau très fins autour des bulles d'air de la mousse, selon une architecture spécifique. Des chercheurs de l'INRA, du CEA et du CNRS ont étudié l'une de ces molécules tensioactives, l'acide gras 12-hydroxy stéarique, issue de l'huile de ricin. Pour parvenir à disperser cette molécule, initialement insoluble dans l'eau, ces chercheurs lui ont ajouté un sel, et ont ensuite démontré ses propriétés très avantageuses qui, même en faible quantité, produit une mousse abondante et, surtout, stable pendant plus de 6 mois, contrairement aux tensioactifs classiques qui ne stabilisent les mousses que quelques heures. Utilisant la microscopie et la diffusion de neutrons, les chercheurs ont pu observer et expliquer ce phénomène. Ainsi, ils ont montré que dans une gamme de températures moyenne entre 20 et 60° C, l'acide gras 12-hydroxy stéarique, mélangé avec le &quot;bon&quot; sel se disperse dans l'eau sous la forme de tubes de quelques microns. Ces derniers forment alors une structure parfaitement stable et rigide dans les films d'eau très minces placés entre les bulles d'air, ce qui explique la tenue de la mousse. Mais au-delà de 60° C, ces tubes fusionnent sous la forme d'assemblages sphériques mille fois plus petits (soit quelques nanomètres), que les chercheurs appellent des &quot;micelles&quot;. La mousse s'effondre alors, la structure rigide disparaissant. Les chercheurs ont montré que cette transition d'un assemblage de tubes à un assemblage de micelles est &quot;réversible&quot;. Ainsi si l'on augmente la température d'une mousse, son volume va diminuer dès la formation de micelles, et si on la baisse à nouveau la température entre 20 et 60° C, les tubes se reforment et la mousse se stabilise une nouvelle fois. Cela dit, pour retrouver le volume de mousse initial, il faudrait néanmoins réinjecter de l'air. Les résultats de ces travaux, qui viennent d'être publiés dans la revue Angewandte Chemie du 29 août, constituent une première. C'est en effet la première fois qu'une mousse aussi stable est obtenue à partir d'une molécule tensioactive aussi simple et d'origine naturelle. Cela ouvre des perspectives d'autant plus intéressantes que les mousses sont amplement utilisées dans l'industrie. Par exemple, les industriels pourraient ainsi produire des détergents ou des shampoings dont il serait possible de contrôler la quantité de mousse par simple effet de la température, facilitant ainsi son évacuation. Dans le secteur des cosmétiques, certains produits nécessitent de nombreux éléments chimiques afin d'obtenir une mousse stable. Or l'utilisation de l'acide gras 12-hydroxy stéarique permettrait alors de limiter la quantité d'éléments synthétiques tout en conservant les propriétés &quot;moussantes&quot; plus longtemps.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67561.htm</fichier>
      <numero>260</numero>
      <date>30/08/2011</date>
      <rubrique>Evénement</rubrique>
      <titre>Colloque &quot;Durabilité intrinsèque de la chimie : procédés et catalyse&quot;</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>Renseignements : tél. +33 (0)4 42 11 22 33</contact>
      <texte>Le 20 septembre 2011, à Nice, le PRIDES (Pôles Régionaux d'Innovation et de Développement Economique Solidaire) NOVACHIM et les pôles de compétitivité PASS et TRIMATEC, en partenariat avec l'Université de Nice Valrose et l'Institut de Chimie de Nice, organisent un colloque intitulé &quot;Durabilité intrinsèque de la chimie : Procédés et Catalyse&quot;. L'occasion pour les universitaires et les entreprises d'évoquer, à travers des témoignages et des présentations didactiques, les derniers développements dans ces domaines et leurs pistes de travail respectives. Un rendez-vous d'information technique sur les procédés et la catalyse qui s'inscrit dans la vision d'une chimie durable qui impose aujourd'hui d'étendre la vision d'optimisation à l'ensemble des impacts des procédés.</texte>
      <images/>
    </bulletin>
    <bulletin>
      <fichier>67794.htm</fichier>
      <numero>261</numero>
      <date>29/09/2011</date>
      <rubrique>Focus</rubrique>
      <titre>9 milliards d'hommes à nourrir : un défi majeur !</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>François Bourin Editeur - www.bourin-editeur.fr</contact>
      <texte>C'est sans doute pour l'humanité le défi majeur de ces 40 prochaines années. D'ici 2050, alors que la Terre comptera environ 9 milliards d'êtres humains, iil faudra en effet réussir à produire en quantité croissante une nourriture répondant à des normes de qualité exigeantes, ceci en respectant mieux l'environnement. D'où le titre de l'ouvrage co-écrit par Marion Guillou, Présidente de l'Institut National de la Recherche Agronomique (INRA), et Gérard Matheron, Président du Centre de coopération Internationale en Recherche Agronomique pour le Développement (CIRAD), et publié par François Bourin Editeur. Confronté à cet extraordinaire défi, l'homme peut éviter un cataclysme selon les auteurs de cet ouvrage, &quot;mais cela nécessitera de profonds changements, notamment dans nos habitudes de consommation et de production ici en Europe&quot;, concluent-ils dans la quatrième de couverture. L'ouvrage de Marion Guillou et Gérard Matheron Crédits : Francois Bourin Editeur &quot;Combien de civilisations se sont-elles effondrées, faute de sécurité alimentaire, ou plus précisément par incapacité de leur agriculture à satisfaire les besoins de la population dans un contexte de surexploitation des ressources naturelles ou de dégâts environnementaux irréversibles&quot;, s'interrogent les auteurs en introduction de leur ouvrage. Une question qui mérite d'être posée alors que l'humanité comptera officiellement 7 milliards d'êtres humains en novembre prochain et 9 milliards d'ici 2050, c'est-à-dire demain, dans moins de 40 ans. Se pose alors évidemment une autre question, majeure, celle de nourrir une telle population. &quot;C'est une question que tout le monde se pose mais qui est abordée le plus souvent par le petit bout de la lorgnette en évoquant les récentes émeutes de la faim ou l'achat de terre en Afrique par tel ou tel spéculateur&quot;, explique Marion Guillou. Or les deux auteurs, du fait des fonctions qu'ils occupent et de leur parcours professionnel, observent depuis longtemps se qui se passe dans l'agriculture, l'alimentation et l'environnement, au nord comme au sud. Qui plus est, ils se connaissent bien, d'où l'envie de &quot;donner à voir&quot; à un large public ce que la science a produit durant ces dernières années autour de ces sujets afin de faire partager à chaque lecteur leur compréhension de ce paysage, même s'il n'est pas simple. Nécessité de ne pas prolonger les tendances actuelles Leur diagnostic est sans appel : &quot;Oui nous allons nourrir les 9 milliards d'être humains que comptera la Terre en 2050 mais ... à la seule condition de ne pas prolonger les tendances actuelles&quot;, déclarent-ils. Pour Marion Guillou et Gérard Matheron, il est urgent de réagir en tant qu'individu, en tant que citoyen, l'INRA et le CIRAD, les organismes qu'ils président, devant également réagir, &quot;parce que le temps de la recherche se mesure en dizaines d'années&quot;. Sélectionner une plante résistante à la sécheresse, cela demande en effet une quinzaine d'années de travail. &quot;Au cours de ces trente dernières années, l'agriculture a été très mal traitée dans l'agenda international, notamment par les bailleurs de fonds et une certaine vision politique. Aussi avons-nous décidé d'écrire ce livre pour que l'agriculture revienne sur le devant de la scène&quot;, explique Gérard Matheron. Une chose est sûre : il va falloir inverser les tendances, sinon nous courrons à la catastrophe. Un exemple, celui du gaspillage où des évolutions importantes sont impératives, évolutions qui dépendent, certes, des connaissances scientifiques mais également du comportement de chacun et de la politique. Autre constat des auteurs de l'ouvrage, il ne sera pas possible dans chaque endroit de la planète de nourrir la population qui y habite à partir de ce qu'elle produit. Avec le changement climatique, les pays du sud vont être frappés en effet de la double peine. D'un côté, la production de leurs terres cultivées va diminuer, de l'autre ils disposeront de moins de terres pour l'agriculture. Aussi devront-ils accroître leurs échanges avec les pays du nord. &quot;Pour autant, les pays du sud doivent remettre l'accent sur le développement de l'agriculture paysanne et investir dans les cultures vivrières et des céréales, c'est capital pour s'en sortir&quot;, déclare Gérard Matheron. &quot;Vous ne sortirez pas les populations rurales de la pauvreté si vous ne redéveloppez pas l'agriculture locale&quot;, confirme Marion Guillou. Innover et changer notre manière de consommer S'appuyant sur 43 années de données rétrospectives collectées dans tous les pays du monde, les auteurs de cet ouvrage ont essayé de se projeter sur les 40 prochaines années et de proposer deux scénarios. Le premier d'entre eux montre la poursuite de la tendance actuelle, avec des disparités alimentaires qui s'échelonnent selon les différentes régions du monde entre 2 500 et 4.000 kcalories par jour. Le second, est un scénario de rupture, avec 3.000 kcalories par personne, dont 500 kcalories d'origine animale, pour l'ensemble de la population du globe. &quot;Il s'agissait de montrer quel serait l'impact de cette consommation de viande dans les régimes sur les besoins nécessaires en termes de surfaces agricoles pour produire cette viande&quot;, précisent-ils. Ni pessimiste, ni optimiste, Marion Guillou et Gérard Matheron, en scientifiques qu'ils restent avant tout, se veulent objectifs et réalistes. &quot;Il est possible d'éviter le cataclysme qu'envisagent certains. Cela suppose évidemment d'innover considérablement, à tous les niveaux, mais surtout nécessite de changer profondément nos comportements alimentaires et, plus généralement, notre manière de consommer&quot;.</texte>
      <images>
        <image>
          <url>http://www4.utc.fr/~lo17/IMAGESWEB/67794_01.jpg</url>
          <legende>L'ouvrage de Marion Guillou et Gérard Matheron</legende>
        </image>
      </images>
    </bulletin>
    <bulletin>
      <fichier>67795.htm</fichier>
      <numero>261</numero>
      <date>29/09/2011</date>
      <rubrique>Focus</rubrique>
      <titre>AgroParisTech : son nouveau Directeur Général entre bilan et perspectives</titre>
      <auteur>ADIT - Jean-François Desessard - email : jfd@adit.fr</auteur>
      <contact>AgroParisTech - Gilles Trystram - email : gilles.trystram@agroparistech.fr</contact>
      <texte>Issu de la fusion en 2007 de trois établissements d'enseignement supérieur - Ina P-G, Engref, Ensia - AgroParisTech est un établissement d'enseignement supérieur réputé mondialement dans les sciences du vivant. Sa mission est de former des ingénieurs mais aussi de produire et de diffuser des connaissances, provenant de la recherche et du développement, en partenariat avec les grands organismes de recherche et les principaux centres techniques. Nommé depuis le 1er septembre dernier, son nouveau Directeur Général, Gilles Trystram, dresse un bilan des actions entreprises tout en évoquant le travail restant à accomplir. Gilles Trystram, Directeur Général d'AgroParisTech Crédits : AgroParisTech BE France - Depuis la fusion, vous occupiez la fonction de directeur adjoint d'AgroParisTech, parallèlement à celle de directeur délégué du Centre AgroParisTech de Massy. Quel bilan dressez-vous de ces quatre dernières années ? Gilles Trystram - L'installation d'AgroParisTech, issu de la fusion de trois établissements d'enseignement supérieur, constituait un challenge quand elle a été lancée en 2007. Or je crois que nous avons su relever ce défi qui nous était proposé. J'en veux pour preuve qu'AgroParisTech a acquis aujourd'hui une véritable identité reconnue tant au niveau national qu'international. Qui plus est, nous avons démarré, dès l'année passée, un nouveau cursus unique conçu à partir des trois cursus existants, ce qui, là encore, représentait un défi. C'est donc pour nous un véritable motif de satisfaction. Enfin, AgroParisTech, en restant une école d'ingénieur a aussi installé un cadre de formation en master et doctorat et présente désormais un profil qui le rend attractif, en particulier pour les étudiants étrangers, dont la proportion parmi nos effectifs a d'ailleurs augmenté. BE France - Quels vont être les principaux défis pour AgroParisTech au cours des prochaines années ? Gilles Trystram - D'ici cinq ans, nous allons nous installer à l'extérieur de Paris, sur le plateau de Saclay, dans le cadre de la création d'un grand site universitaire collectif. Il s'agit là d'une évolution significative puisque cette installation va entraîner la fermeture de nos 4 sites actuels en Ile-de-France. Parallèlement, nous allons achever la réforme pédagogique que nous avons engagée et qui se met progressivement en place. Par ailleurs, nous souhaitons développer la recherche et en particulier nos partenariats avec le monde socio-économique. Enfin, si nous pouvons être satisfaits d'enregistrer davantage d'inscriptions d'étudiants étrangers à nos cursus, il est indispensable que le nombre d'étudiants, déjà significatif, que nous envoyons à l'étranger, soit plus important. BE France - Vous venez d'évoquer le nécessaire développement de la recherche au sein d'AgroParisTech. Est-ce à dire que l'équilibre actuel entre recherche et formation va changer ? Gilles Trystram - AgroParisTech reste un établissement d'enseignement supérieur adossé à une recherche qui se veut et doit être au meilleur niveau possible. Il n'y a donc aucune ambiguïté : nous formons des ingénieurs, des masters et des docteurs, ce qui nécessite de faire de la recherche si l'on souhaite rester au meilleur niveau mondial. Cela dit, nous ne sommes pas un organisme de recherche du type INRA ou CNRS. Nous devons donc préserver cet équilibre entre formation et recherche. Parallèlement, l'analyse stratégique que nous avons menée nous a permis d'identifier les domaines qu'il nous faut renforcer ou développer. Par exemple, dans le nouveau cursus, nous avons ouvert de nouvelles formations d'ingénieur qui doivent nécessairement s'appuyer sur une recherche au plus haut niveau. BE France - Vous parlez également d'un développement de vos partenariats avec l'industrie et plus généralement le monde économique. Qu'en est-il des pôles de compétitivité ? Gilles Trystram - AgroParisTech étant une école d'ingénieur adossée à une recherche au meilleur niveau, il est indispensable que nous soyons en interaction permanente avec les entreprises. Nous pouvons le faire de différentes manières, soit en créant des chaires d'entreprises, comme nous l'avons fait à plusieurs reprises ces dernières années, soit en collaborant directement avec des entreprises, les exemples sont nombreux et notre histoire montre que cela ne date pas d'aujourd'hui, soit encore en passant par le biais des pôles de compétitivité comme Vitagora. Ce sont de véritables catalyseurs de compétences et de savoir-faire qui permettent d'accompagner en particulier les entreprises dans leur démarche d'innovation. C'est la raison pour laquelle nous allons signer très prochainement une convention de coopération avec Vitagora, le pôle de compétitivité Bourgogne Franche-Comté dont certains des axes de recherche rejoignent les thématiques d'AgroParisTech. Je pense en particulier à l'alimentation. Il s'agit d'une &quot;première&quot; puisque jusqu'ici nous n'avions signé que des accords de participation ou d'association avec d'autres pôles de compétitivité.</texte>
      <images>
        <image>
          <url>http://www4.utc.fr/~lo17/IMAGESWEB/67795_01.jpg</url>
          <legende>Gilles Trystram, Directeur Général d'AgroParisTech</legende>
        </image>
      </images>
    </bulletin>
  </bulletins>
</corpus>
